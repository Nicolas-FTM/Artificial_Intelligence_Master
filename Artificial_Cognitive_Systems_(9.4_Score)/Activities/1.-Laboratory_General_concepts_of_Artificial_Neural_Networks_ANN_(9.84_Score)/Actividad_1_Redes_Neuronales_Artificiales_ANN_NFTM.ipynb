{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiDzBoKGwmMZ"
   },
   "source": [
    "# REDES NEURONALES\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeO2xVqBv1fx"
   },
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhzeF2BVvvi7"
   },
   "source": [
    "\n",
    "\n",
    "En esta actividad vamos a utilizar una red neuronal para clasificar imágenes de prendas de ropa. Para ello, utilizaremos Keras con TensorFlow.\n",
    "\n",
    "El dataset a utilizar es Fashion MNIST, un problema sencillo con imágenes pequeñas de ropa, pero más interesante que el dataset de MNIST. Puedes consultar más información sobre el dataset en [este enlace](https://github.com/zalandoresearch/fashion-mnist).\n",
    "\n",
    "El código utilizado para contestar tiene que quedar claramente reflejado en el Notebook. Puedes crear nuevas celdas si así lo deseas para estructurar tu código y sus salidas. A la hora de entregar el notebook, **asegúrate de que los resultados de ejecutar tu código han quedado guardados**. Por ejemplo, a la hora de entrenar una red neuronal tiene que verse claramente un log de los resultados de cada epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "gSHr268SwmMa"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import initializers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zScMKU2OKSPD"
   },
   "source": [
    "En primer lugar vamos a importar el dataset Fashion MNIST (recordad que este es uno de los dataset de entranamiento que estan guardados en keras) que es el que vamos a utilizar en esta actividad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4voG2hxxG4h3"
   },
   "outputs": [],
   "source": [
    "mnist = fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JphLsCvgKrzb"
   },
   "source": [
    "Llamar a **load_data** en este dataset nos dará dos conjuntos de dos listas, estos serán los valores de entrenamiento y prueba para los gráficos que contienen las prendas de vestir y sus etiquetas.\n",
    "\n",
    "Nota: Aunque en esta actividad lo veis de esta forma, también lo vais a poder encontrar como 4 variables de esta forma: training_images, training_labels, test_images, test_labels = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1muD4PHEG4h6",
    "outputId": "2f6beb46-3176-4adf-a64b-6dab9ea81bbe"
   },
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWGpJqVVLT3Y"
   },
   "source": [
    "Antes de continuar vamos a dar un vistazo a nuestro dataset, para ello vamos a ver una imagen de entrenamiento y su etiqueta o clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "id": "t5a5PlswG4h8",
    "outputId": "2edeb68d-fcba-4f20-c49a-f80a5c51b012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=200)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(training_images[0], cmap=\"gray\") # recordad que siempre es preferible trabajar en blanco y negro\n",
    "\n",
    "print(training_labels[0])\n",
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCJvZx3MLucY"
   },
   "source": [
    "Habréis notado que todos los valores numericos están entre 0 y 255. Si estamos entrenando una red neuronal, una buena practica es transformar todos los valores entre 0 y 1, un proceso llamado \"normalización\" y afortunadamente en Python es fácil normalizar una lista. Lo puedes hacer de esta manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tojL1BmjG4h_"
   },
   "outputs": [],
   "source": [
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaqXlSMBwmMg"
   },
   "source": [
    "## 1. Información sobre el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0aer8ZZwmMh"
   },
   "source": [
    "Una vez tenemos los datos cargados en memoria, vamos a obtener información sobre los mismos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-im9PnEwmMh"
   },
   "source": [
    "**Pregunta 1.1 *(0.25 puntos)*** ¿Cuántas imágenes hay de *training* y de *test*? ¿Qué tamaño tienen las imágenes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lvP0Y4SCwmMi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Número de imágenes de training que existen: 60000.\n",
      "* Número de imágenes de test que existen: 10000.\n",
      "* El tamaño de las imágenes es 28x28.\n"
     ]
    }
   ],
   "source": [
    "print(\"* Número de imágenes de training que existen: {}.\".format(len(training_images)))\n",
    "print(\"* Número de imágenes de test que existen: {}.\".format(len(test_images)))\n",
    "print(\"* El tamaño de las imágenes es {}x{}.\".format(training_images[0].shape[0], training_images[0].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha usado las variables training_images y test_images que son las variables que representan las imágenes que se usarán para ajustar y evaluar el modelo de red neuronal. Las variables training_images y test_images son arrays tridimensionales <x,y,z> que contienen en la primera posición (x) la imagen asociada a los pixeles en la segunda y tercera posición (y,z). \n",
    "\n",
    "Sería similar a tener una lista de 60000 posiciones, donde cada elemento es un pixel en una matriz bidimensional de tamaño 28x28."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2LsvfHOwmMk"
   },
   "source": [
    "**Pregunta 1.2 *(0.25 puntos)*** Realizar una exploración de las variables que contienen los datos. Describir en qué consiste un example del dataset (qué información se guarda en cada imagen) y describir qué contiene la información en y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3W5rzaGxwmMk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (60000, 28, 28) (28, 28) 0.0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x261426a5910>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(type(training_images), training_images.shape, training_images[0].shape, training_images[0,0,0])\n",
    "print(list(set(training_labels)))\n",
    "plt.imshow(training_images[0], cmap=\"gray\") # recordad que siempre es preferible trabajar en blanco y negro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaEWKFyvwmMm"
   },
   "source": [
    "La respuesta es similar a la anterior. Aquí es importante agregar que la imagen está normalizada ya que nos dan la imagen en 8 bits de profundidad, yendo el valor de los píxeles entre 0 y 255. Por último, interpretamos y como el conjunto de test y las etiquetas asociadas a que imagen es, por lo que contiene lo mismo, es decir, un array tridimensional que en cada posición se guarda la imagen, y un array que relaciona la imagen con la etiqueta correspondiente por orden:\n",
    "\n",
    "\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt', \"Sneaker\", \"Bap\", \"Ankle boot\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI3IAhOQ8zHi"
   },
   "source": [
    "## 2. Creación del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYUWWsszMAKt"
   },
   "source": [
    "Ahora vamos a definir el modelo, pero antes vamos a repasar algunos comandos y conceptos muy útiles:\n",
    "* **Sequential**: Eso define una SECUENCIA de capas en la red neuronal\n",
    "* **Dense**: Añade una capa de neuronas\n",
    "* **Flatten**: ¿Recuerdas cómo eran las imágenes cuando las imprimiste para poder verlas? Un cuadrado, Flatten toma ese cuadrado y lo convierte en un vector de una dimensión.\n",
    "\n",
    "Cada capa de neuronas necesita una función de activación. Normalmente se usa la función relu en las capas intermedias y softmax en la ultima capa (en problemas de clasificación de más de dos items)\n",
    "* **Relu** significa que \"Si X>0 devuelve X, si no, devuelve 0\", así que lo que hace es pasar sólo valores 0 o mayores a la siguiente capa de la red.\n",
    "* **Softmax** toma un conjunto de valores, y escoge el más grande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgBW1yE2MwPp"
   },
   "source": [
    " **Pregunta 2.1 (2 puntos)**. Utilizando Keras, y preparando los datos de X e y como fuera necesario, define y entrena una red neuronal que sea capaz de clasificar imágenes de Fashion MNIST con las siguientes características:\n",
    "\n",
    "* Una hidden layer de tamaños 128, utilizando unidades sigmoid\n",
    "Optimizador Adam.\n",
    "* Durante el entrenamiento, la red tiene que mostrar resultados de loss y accuracy por cada epoch.\n",
    "* La red debe entrenar durante 10 epochs y batch size de 64.\n",
    "* La última capa debe de ser una capa softmax.\n",
    "* Tu red tendría que ser capaz de superar fácilmente 80% de accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aTaD2QXIORwu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5424 - accuracy: 0.8152 - val_loss: 0.4790 - val_accuracy: 0.8300\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 561us/step - loss: 0.3913 - accuracy: 0.8587 - val_loss: 0.4177 - val_accuracy: 0.8542\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 574us/step - loss: 0.3550 - accuracy: 0.8706 - val_loss: 0.3812 - val_accuracy: 0.8626\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 562us/step - loss: 0.3320 - accuracy: 0.8792 - val_loss: 0.3636 - val_accuracy: 0.8683\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 594us/step - loss: 0.3134 - accuracy: 0.8853 - val_loss: 0.3780 - val_accuracy: 0.8621\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 583us/step - loss: 0.2975 - accuracy: 0.8914 - val_loss: 0.3561 - val_accuracy: 0.8720\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 586us/step - loss: 0.2846 - accuracy: 0.8955 - val_loss: 0.3376 - val_accuracy: 0.8781\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 577us/step - loss: 0.2728 - accuracy: 0.9001 - val_loss: 0.3361 - val_accuracy: 0.8743\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 594us/step - loss: 0.2630 - accuracy: 0.9037 - val_loss: 0.3363 - val_accuracy: 0.8761\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 583us/step - loss: 0.2532 - accuracy: 0.9063 - val_loss: 0.3290 - val_accuracy: 0.8810\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Parametros\n",
    "###########################################\n",
    "\n",
    "# Tamaño de cada imagen\n",
    "sz_image = [28,28]\n",
    "\n",
    "# Numero de neuronas en la capa oculta\n",
    "sz_hid_layer = 128\n",
    "\n",
    "# Funcion de activacion de la capa oculta\n",
    "fun_hid_layer = \"sigmoid\"\n",
    "\n",
    "# Funcion de optimizacion\n",
    "opt = \"Adam\"\n",
    "\n",
    "# Iteraciones del entrenamiento de la red neuronal\n",
    "ep = 10\n",
    "\n",
    "# Tamaño del lote\n",
    "sz_batch = 64\n",
    "\n",
    "# Funcion de activación en la salida\n",
    "fun_output_layer = \"softmax\"\n",
    "\n",
    "# Tipos distintos de tags que clasifican las imagenes\n",
    "tags = len(list(set(training_labels)))\n",
    "\n",
    "# Metricas\n",
    "metr = [\"accuracy\"] \n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "# Creacion del Modelo\n",
    "###########################################\n",
    "\n",
    "# Creamos el modelo de Red Neuronal secuencial\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Creamos la capa de entrada\n",
    "model.add(keras.layers.Flatten(input_shape = sz_image))\n",
    "\n",
    "# Creamos una única capa oculta con 128 neuronas\n",
    "model.add(keras.layers.Dense(sz_hid_layer, activation = fun_hid_layer))\n",
    "\n",
    "# Creamos la capa de salida\n",
    "model.add(keras.layers.Dense(tags, activation = fun_output_layer))\n",
    "\n",
    "# Modificamos los parámetros del modelo\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = opt, metrics = metr, steps_per_execution = sz_batch)\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "# Ajuste del Modelo\n",
    "###########################################\n",
    "\n",
    "adj_model = model.fit(training_images, training_labels, epochs = ep, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bxr5hTKYOQnK"
   },
   "source": [
    "Para concluir el entrenamiento de la red neuronal, una buena práctica es evaluar el modelo para ver si la precisión de entrenamiento es real\n",
    "\n",
    "**pregunta 2.2 (0.5 puntos)**: Evalúa el modelo con las imágenes y etiquetas test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VNjQEtUUG4iI"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp8AAAGyCAYAAACiMq99AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABm7ElEQVR4nO3dd3wUZeIG8Ge2l2x6IyEQehNCx2CjKYpyYBdQEU9soGJ+noqnoOcpVg7vLByeoJ4gWNETRBDFAggIBFF6DSW9brbvzvz+2M1mN9mEbEh2U57v57Of3Zl5Z+bdTDQPb5kRJEmSQEREREQUArJwV4CIiIiI2g+GTyIiIiIKGYZPIiIiIgoZhk8iIiIiChmGTyIiIiIKGYZPIiIiIgoZhk8iIiIiChmGTyIiIiIKGYZPIiIiIgoZhk8iIiIiCpmgw+ePP/6IiRMnIiUlBYIgYPXq1efcZ9OmTRg8eDDUajW6d++Od999txFVJSIiIqLWLujwaTKZkJGRgTfeeKNB5Y8fP46rr74ao0ePRnZ2NubMmYO77roL33zzTdCVJSIiIqLWTZAkSWr0zoKAzz//HJMnT66zzGOPPYY1a9bg999/96675ZZbUFZWhnXr1jX21ERERETUCima+wRbt27FuHHj/NaNHz8ec+bMqXMfm80Gm83mXRZFESUlJYiLi4MgCM1VVSIiIiJqJEmSYDQakZKSApms7s71Zg+feXl5SEpK8luXlJSEiooKWCwWaLXaWvssWLAAzzzzTHNXjYiIiIia2KlTp9CxY8c6tzd7+GyMuXPnIisry7tcXl6OTp064fjx4zAYDM1+fofDge+//x6jR4+GUqls9vNR+PGatz+85u0Tr3v7w2seOkajEV26dDlnVmv28JmcnIz8/Hy/dfn5+YiMjAzY6gkAarUaarW61vrY2FhERkY2Sz19ORwO6HQ6xMXF8Re1neA1b394zdsnXvf2h9c8dKp+vucaItns9/nMzMzExo0b/dZt2LABmZmZzX1qIiIiImphgg6flZWVyM7ORnZ2NgD3rZSys7ORk5MDwN1lfvvtt3vL33vvvTh27BgeffRRHDhwAG+++SY++ugjPPzww03zDYiIiIio1Qg6fP76668YNGgQBg0aBADIysrCoEGDMG/ePABAbm6uN4gCQJcuXbBmzRps2LABGRkZePXVV/Gf//wH48ePb6KvQEREREStRdBjPkeNGoX6bg0a6OlFo0aNwu7du4M9FRERERG1MXy2OxERERGFDMMnEREREYUMwycRERERhQzDJxERERGFDMMnEREREYUMwycRERERhQzDJxERERGFDMMnEREREYUMwycRERERhQzDJxERERGFDMMnEREREYUMwycRERERhQzDJxERERGFDMMnEREREYUMwycRERERhQzDJxERERGFDMMnEREREYUMwycRERERhQzDJxERERGFDMMnEREREYUMwycRERERhQzDJxERERGFDMMnEREREYUMwycRERERhQzDJxERERGFDMMnEREREYUMwycRERERhQzDJxERERGFjCLcFSAiIiJqNSQJEJ01Xq7qzy6H/7LfdkfgfaqWXefYXt/+rpp18pTpcTkw7M/h/qn5YfgkIiKi5lcVrlx2T8jy+RxwfX3baqx32T3bam+XO+0YnnsG8pXvA1LNQBcoPNazTXS6j9GaRKWGuwa1MHwSERG1VlWtcE6bO3Q5rT6ffd9tgNMeIKTZ3WGr6rPoDLy+QWHRUf/xJDEsPyIZgA4AUNHMJxJkgEwJyBSel9znswKQK+rYpqxdtmpZrgx8rIAvnzJyn2PG92rmLx48hk8iIqJguJyeMFcz5Fk9Aa+ubQFCodMaICiea1uN80AK90+kkQRAoXaHL7kSkKs87z6fZeez3v3ukmT4bd8B9M8YBIVS3bTBruolyAEZp9E0FMMnERG1TKLo0/Jm9wlgDnfwctmrW/MauF1mt+CC04cgW7sRkJz1hELf1sIaYbIld7sKcnegU6gBuRpQqDzvak8YCxDY5Kq6A2Cw64PZRyYPyY9EdDiQU7AWF2RMAJTKkJyT6sfwSUTUnomu6mAVMMA5mmF71ecA2333FZ1N/nXlALoBQGFTHVHwCXo+Ic/7rqkdAOsLh+dbPkSBjuh8MHwSEbUkkuRujXNY3C+nFXCYq5cdFsBpqWPZp2ytMlXbPO9VLXthGofXKDKFT+tdVcBTuoOXXFmjdU/lCWUqv+0uQY6jJ06jW88+kKu0NYJdoOBYc53avb7qs0wBCEK4fzJErQrDJxHRuUiSu1XOL7xZ6w+EDSlTax/PunCqEdaqw51vmAsU/s61PVA4DHL/JmjVEx0O7F+7Fl0unQA5u2CJwoLhk4haL5fTJ8CZ62j5C7TODJnNjIEnD0H++WcNC5bhaCGUKQGl1v1SaAClrnrZb53nveZyfWV8u4h9xwKyFY+ImhnDJxE1rZrdxn6tgHUFxLrKWmoEwhrrREejqykH0BkASoLcUZD5h0CFtkYgrPrsGwDPUSZgsNS6b81CRNTG8P9sRO2JJLnH+tkrAVsFYKsEbMY6Ql893cd1hcFwdht7A11VK5+27mCn1MIlU+Hg0Rz0umAg5JqIwPsHCo1sHSSiIEhOJySbDaLdDslmg+R5F21292e7zbNsg2R3eMq4y4k2e41lGySf/fyWbTaIdp9jeM4Zc9NNSHr8sXD/GPwwfBK1Bk6bOyRWveyVdSx7QqXfshGwG6uXz6O1MGgy5TnCYD0tf37hr2ZXcs1ymqADoehw4LBpLXoM59i/lkgSRUhWq/uPq8UC0Wp1L/u8ixYLJKsNotX33QrRaoNktfi/e44hWq3oZDLh1H8/gEyphFDXS+W/jDrLqhq0f10vKBQQ+I+ZJiOJIiCK7neXC5JLhMtmhbyyEo68PEgulycE+oQ+32XfgFcVFO0+QdETBP2WbTaIDnv1Pp79qsImxPBO6hMtYR5HHgDDJ1FzaVBgDBAOvdt8WiabIzAq9YA6AlBFACq9T5irIyAGDIPnCIjsNm5TJEly/8G1WKpDoTcc+oa/GkHREiA4WgMFR5u7jMUCyW5vtu+hAWDLzW224wer/nAb5CtA6PUeW64ARHcg83sXRcAlQhJdfu+QRP+yLpdPuKtRVnRBEqXqMgHK+h1HClDW5ao+Z8DjBF7vt38dugE4GbpLWjelEjKVCoJKBUGthqBWeZbV3mVBpYKsalml8pSpsVz1WaUOuCyoPOvUasgNhnB/61r4l4HIl9MG2CsCtB6eozUx1IFRbXCHRrWh+uVdjgDUkf7LKoPPNk9Z3g+wTRNtNogVFXAZKyEafd4rjBArjRBNptothBYrJJs7LIo2KyRL7SAJKfRP0xFUKgharfuPqVYDmUYLQaP2e5dpNBA0mup3bY1lz7sol2P7tm0YNmgw5JIIyeHwf9kdtdfV+7LXWof6jhMgVHv3CflPtp1RKr2BTFCrIFNWBUC1J6z5hEDf0OcbFNVqd2u3b3BUq937VR3D55jeEFgVOOX8/y7A8EltlcMCWEoBcwlgKQnwudRvvcJSgmvMpZDvbvqbWtcZGP3CoiFAQGz+wCg5nRCtNggKuft/luz+axEkUXSHQ6MRLqPR/e4Jja4Ko3+YNFZ6QqbRr3xzthwCAORyyLRan2BXIwRqNRDUVSFQC5lGXSMMeoKjVgtB7X6vFSA1GvfvZRP+wXY4HDCXlEB/6SVQhmG4hbfFr75AWyu41g643sAaTHh2OSHI3I+BFOQyQCb3fxdkgFzmLuN9l0OQCX5l/csEOI5MDsiEGseRua+jUMe5ZTJPveS136v2kcvd56t6D3Ruudz9/zGfsk5RxNfffIMJ11wTlmtOtTF8UsvmcroDYsAAWfNzafXnICe9CHDPfvZS6hrQuti0gVGSJPdYoapxblYrxFIbJFsJROtZ97giqxWS1eZunfK+u9eJthrbfI/jffeU8azz66YShNp/+D2tTO7goK1ep/bZ5hcutLVbnAKECqGNPwNZstvhqqyst+XRHSI9YbGiorp8ZSVEo7FpWhgFAbKICMgNBsgMBvd7ZCTkhgjI9Hr/61YVIH0Cpf/vQlXLo+edf8QbRRAE9zhPhQLQasNdnXZBcDj43PUWhuGTQkMU3V3SlhJPq6MnUHpDY6DPZYCtvPHnlCkAbQygjXW/62I9n6N9PrvXO5SR+H7rToy+chKUumhAroDkcFSHNt+g57vOVLXNAtFa2oAQGGCb3Q7Jc9ywkiRIFgtcIRicLqjV/gHHN9jUFXDVPl2ptVrLaoZeT6hSBP+/OEmSIJnNtVoSg2l5lKzWpvk5KZXusBgR4QmNnhAZaYAswvNu8ITJqnef8jK9vs0HfSJqfRg+KTiS5L6lTp2hsY5gaSkDpLoHg5+TJsodFnWx1YHS57OkjoYIDURJC1FSQXQpINoBl8kE0WR2d2FWmCDmmiBWVkI0FUI0n4BoMsFVaYKrshLJJSU4/o93PAHSVu/g9WanULjDmEbjfRc0ancg875Xb5Np1BDUNcpoPIHNs62q21NQ19ymhuR0ecf61Rr75zuJxDsGMECZmuME/Saj+Idr7wzR8vP4x0VDKJV1Blyo1UgpLsaZTz+FVGnya4Fsqmsv0+v9Wxy9IdITFn1DpDdMVpeXqdVNUg8iopaE4ZPcJAkoPgqc3g6YCusdHwnXebTQKfWe1sYYiMpoiLJIiDIDROghQgtRVEMUlXA55RCdMoh2QLS73AGy0OQOkSYTRFMJXKYcb7CUmqC1TgmgrsjhFwLV6oYFQ9/Q5xcIa4Q/v2NrGt1id94i9M16eEkUq4cO1Lh1jvuWOVa/QFt3wPW9bY7PTGmf0OvlcEB0ONzd2IG+MoA6f3MUitotjn7d11XLNcJk1faICE4uICIKgOGzPTMVAcc2Ace+B479AJSfqre4JAGSU4DLKYPoUkGUR7nDI/QQBZ0nOKrgEhUQnXKIDkC0Se7waHVAtNghms0QKyvhMlcAjuKm/05KJeQ6nbvFSa+HLCKi+rNeD1mE+13uty4ColqNX3bvxkVjxkAVEeHfUqhScSJOExBkMnero1YLxMQ023n8bgdUFWxttloB11Fpwt7duzBgxAioYmJqdWMLWi2vOxFRM2D4bE8cFiBnK3D0e3fgzNsLl0OA3aiA3SiHvTIKDikJLlEN0SF4wqMI0eZ0B0erLcAkCJPn1XiCVusJgjpPMKwRGH1Co19wrBUsIyBTqRr3o3E4YC0qgrpHD86GbOUEQYCgVgNqNeprd3Q4HChXKWGYMIHXnIgohBg+2zJRBPL2QDr4Ley7N8J+cC/s5RLsFQpP4EyC01rzz3Ol51UPmax2ONTr3F2UOn0drY6eYFkzMOp04eliJiIiorDgX/02QhJFOPPzYd/7C+y7N8F+YA9sp87CXibBYZIDkgAgMuC+8thYqNLT3a9OnSCPjq4VLuU+LY/sjiQiIqLGYvhsZVxlZbCfOAHbiROwnzgB+9HDsB/eD/uZAkiOmtNlqls1BbUSqk5pUHfvBVWX9Oqw2bkz5FFRof0SRERE1G4xfLZAotUK+8kc2I8fdwdMn5errKzuHQUJqggXVIkGqLp0garfcKgGXgJV1+5QJCawtZKIiIjCjuEzTCSnE46zZ2uFS9uJE3Ceza13X4XWBZXBCVWk0/2emgz1gEwoh1wFodulgCZw9zoRERFRuDF8NiNJkuAqKvLvJj/ueT91CnA46txXptdAFauAWl0BlbbSHTINTqgMLsiiEoCuY4Fuo4Guo4DIlNB9KSIiIqLzwPDZBFyVldWhssZLNNV9GyJBrYaqc2eoOqVCFSWDSlkEleMQVOJxyFUivL3kSh3Q+ZLqsJnYF2AXOhEREbVCDJ8NJNrtcJw65R8uj5+A7eQJuAqL6t5RJoMyNbV6gk96Z/fEH00FFBW/QTixCTi9svrRk0oAggxIGeoOmt1GAx2HAQo+Zo+IiIhaP4bPGkSTCeaduxC1dSsK9+6F82QO7CdOwHHmjPu+mXWQJ8RD3TndfyZ5ejqUaWmQKZVA0SHPzd3/B/z0M2Cv8bi/2K5AV0/LZpdL3I+gJCIiImpjGD5rsOfk4OzddyMJQHmNbTK93i9Y+rZmyg0G/8LGfOD4D8CaV9yPsDSe9d+ujXUHzapXTOfm+kpERERELQbDZw2qzp2h7NoVpRoNOo4YDk3XrlB7QqY8Pr7u2xXZTcDJLZ7WzU1AwR/+2+VqoHNmdetm8gBAJmvur0NERETUojB81iDT6dD5i9X4Y+1aDKzvmc+iCzi72/2M9KObgFPbANF39roAdBjgadkcDXS6EFBqQ/ANiIiIiFouhs+GkiSg5Jg7bB7bBBz/EbDW6JiP6gR0G+UOm10uA/Rx4agpERERUYvF8FkfczFwakt162Z5jv92TRTQ5dLq1s3YrrwFEhEREVE9GD5rKsuBbNsSXHbgf1DsPglAqt4mUwJpIzytm2OAlIGATF7HgYiIiIioJobPmhwWyLf+C9FVy4n9qm/u3nkkoNKHr25ERERErRzDZ03xPeEaOhPZhXIMmPwAlDEdw10jIiIiojajUff6eeONN5Ceng6NRoMRI0Zg+/bt9ZZftGgRevXqBa1Wi7S0NDz88MOwWq2NqnCzEwSI4xfgdOxIICIp3LUhIiIialOCDp+rVq1CVlYW5s+fj127diEjIwPjx49HQUFBwPIrVqzA448/jvnz52P//v145513sGrVKjzxxBPnXXkiIiIial2CDp8LFy7EzJkzMWPGDPTt2xeLFy+GTqfD0qVLA5bfsmULLrroIkydOhXp6em44oorMGXKlHO2lhIRERFR2xPUmE+73Y6dO3di7ty53nUymQzjxo3D1q1bA+4zcuRIfPDBB9i+fTuGDx+OY8eOYe3atbjtttvqPI/NZoPNZvMuV1RUAAAcDgccDkdduzWZqnOE4lzUMvCatz+85u0Tr3v7w2seOg39GQcVPouKiuByuZCU5D8WMikpCQcOHAi4z9SpU1FUVISLL74YkiTB6XTi3nvvrbfbfcGCBXjmmWdqrV+/fj10Ol0wVT4vGzZsCNm5qGXgNW9/eM3bJ1739ofXvPmZzeYGlWv22e6bNm3C888/jzfffBMjRozAkSNH8NBDD+HZZ5/FU089FXCfuXPnIisry7tcUVGBtLQ0XHHFFYiMjGzuKsPhcGDDhg24/PLL6368JrUpvObtD695+8Tr3v7wmodOVU/1uQQVPuPj4yGXy5Gfn++3Pj8/H8nJyQH3eeqpp3DbbbfhrrvuAgD0798fJpMJd999N/76179CJqs97FStVkOtVtdar1QqQ/qLE+rzUfjxmrc/vObtE697+8Nr3vwa+vMNasKRSqXCkCFDsHHjRu86URSxceNGZGZmBtzHbDbXCphyufupQJIkBdqFiIiIiNqooLvds7KyMH36dAwdOhTDhw/HokWLYDKZMGPGDADA7bffjtTUVCxYsAAAMHHiRCxcuBCDBg3ydrs/9dRTmDhxojeEEhEREVH7EHT4vPnmm1FYWIh58+YhLy8PAwcOxLp167yTkHJycvxaOp988kkIgoAnn3wSZ86cQUJCAiZOnIjnnnuu6b4FEREREbUKjZpwNHv2bMyePTvgtk2bNvmfQKHA/PnzMX/+/MacioiIiIjakEY9XpOIiIiIqDEYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGD6JiIiIKGQYPomIiIgoZBg+iYiIiChkGhU+33jjDaSnp0Oj0WDEiBHYvn17veXLysowa9YsdOjQAWq1Gj179sTatWsbVWEiIiIiar0Uwe6watUqZGVlYfHixRgxYgQWLVqE8ePH4+DBg0hMTKxV3m634/LLL0diYiI++eQTpKam4uTJk4iOjm6K+hMRERFRKxJ0+Fy4cCFmzpyJGTNmAAAWL16MNWvWYOnSpXj88cdrlV+6dClKSkqwZcsWKJVKAEB6evr51ZqIiIiIWqWgwqfdbsfOnTsxd+5c7zqZTIZx48Zh69atAff58ssvkZmZiVmzZuGLL75AQkICpk6disceewxyuTzgPjabDTabzbtcUVEBAHA4HHA4HMFUuVGqzhGKc1HLwGve/vCat0+87u0Pr3noNPRnHFT4LCoqgsvlQlJSkt/6pKQkHDhwIOA+x44dw3fffYdp06Zh7dq1OHLkCO6//344HA7Mnz8/4D4LFizAM888U2v9+vXrodPpgqnyedmwYUPIzkUtA695+8Nr3j7xurc/vObNz2w2N6hc0N3uwRJFEYmJiViyZAnkcjmGDBmCM2fO4OWXX64zfM6dOxdZWVne5YqKCqSlpeGKK65AZGRkc1cZDocDGzZswOWXX+4dKkBtG695+8Nr3j7xurc/vOahU9VTfS5Bhc/4+HjI5XLk5+f7rc/Pz0dycnLAfTp06AClUunXxd6nTx/k5eXBbrdDpVLV2ketVkOtVtdar1QqQ/qLE+rzUfjxmrc/vObtE697+8Nr3vwa+vMN6lZLKpUKQ4YMwcaNG73rRFHExo0bkZmZGXCfiy66CEeOHIEoit51hw4dQocOHQIGTyIiIiJqu4K+z2dWVhbefvttvPfee9i/fz/uu+8+mEwm7+z322+/3W9C0n333YeSkhI89NBDOHToENasWYPnn38es2bNarpvQUREREStQtBjPm+++WYUFhZi3rx5yMvLw8CBA7Fu3TrvJKScnBzIZNWZNi0tDd988w0efvhhDBgwAKmpqXjooYfw2GOPNd23ICIiIqJWoVETjmbPno3Zs2cH3LZp06Za6zIzM/HLL7805lRERERE1Ibw2e5EREREFDIMn0REREQUMgyfRERERBQyDJ9EREREFDIMn0REREQUMgyfRERERBQyDJ9EREREFDIMn0REREQUMgyfRERERBQyDJ9EREREFDIMn0REREQUMgyfRERERBQyDJ9EREREFDIMnwFIkhTuKhARERG1SQyfNYiihEc//R0/5ArhrgoRERFRm8PwWcP6fXlYvScXn52Q41/fHWUrKBEREVETYvisYXy/ZDw4phsA4J/fH8Uz/9sHUWQAJSIiImoKDJ81CIKAB0Z3w/XpLgDAu1tO4JGP98DhEsNcMyIiIqLWj+GzDpd2kPDK9RdALhPw2e4zuO+DnbA6XOGuFhEREVGrxvBZj0kDU/DvW4dArZDh2/0FmL50O4xWR7irRURERNRqMXyew7i+SXjvzuGIUCuw7XgJpr69DcWVtnBXi4iIiKhVYvhsgAu7xmHl3RciTq/C3jPluPHfW3G2zBLuahERERG1OgyfDXRBahQ+ujcTKVEaHCs04Ya3tuBoYWW4q0VERETUqjB8BqFbQgQ+vm8kuibocbbcipsWb8XvZ8rDXS0iIiKiVoPhM0ip0Vp8fE8mLkiNRLHJjluW/IJtx4rDXS0iIiKiVoHhsxHiItT4cOaFGNElFpU2J25fuh0b9+eHu1pERERELR7DZyMZNEq8d+dwjOuTCJtTxN3/3YnVu8+Eu1pERERELRrD53nQKOV469YhuHZQKlyihDmrsvHelhPhrhYRERFRi8XweZ6UchlevTEDd4xMBwDM//IPvPbtYUgSnwdPREREVBPDZxOQyQTMn9gXc8b1AAD849tD+NtX+yCKDKBEREREvhg+m4ggCJgzrifmT+wLAFi2+QQe+WQPnC4xzDUjIiIiajkYPpvYjIu6YOFNGZDLBHy26wzu/WAXrA5XuKtFRERE1CIwfDaD6wZ3xL9vHQKVQoZv9+djxrIdMFod4a4WERERUdgxfDaTcX2T8N6M4YhQK7D1WDGmvr0NxZW2cFeLiIiIKKwYPptRZrc4fDjzQsTqVdh7phw3/XsrzpZZwl0tIiIiorBh+Gxm/TtG4aN7MtEhSoOjhSbcuHgrjhVWhrtaRERERGHB8BkC3RMj8Ml9I9E1Xo8zZRbcuHgrfj9THu5qEREREYUcw2eIpEZr8dG9meiXEolikx1TlvyC7cdLwl0tIiIiopBi+Azgh9M/wCyam/y48RFqfHj3hRjeJRZGmxO3vbMN3x3Ib/LzEBEREbVUDJ81FJoL8chPj+DFihfx2M+P4afTP8ElNt19OiM1Srx/53CM7Z0Im1PE3e/vxBfZZ5rs+EREREQtGcNnDQWWAnSN6goXXNiQswH3b7wfV3xyBf6x8x84Vn6sSc6hUcqx+LYhmDwwBU5RwpxV2Xh/64kmOTYRERFRS8bwWUO/uH5YNWEV7o+4H1N6TkG0OhoFlgIs/X0pJq2ehGlrp+HjQx/DaDee13mUchkW3jQQ0zM7Q5KAeV/8gX9tPAxJ4vPgiYiIqO1i+KxDiiIFfxn6F2y8cSP+MeofuKzjZZALcvxW+Bv+tvVvGP3RaDz646PYcnZLo7vlZTIBT/+pHx4c2wMA8OqGQ3j2q/0QRQZQIiIiapsU4a5AS6eSqzCu8ziM6zwORZYifHX0K6w+shpHy4/i6+Nf4+vjXyNZn4yJXSdiUvdJ6BzZOajjC4KArMt7IlqrxN++2oelm4+jwurAC9f1h0LOfxsQERFR28J0E4R4bTzuuOAOfD7pc6y8eiVu7nUzDCoD8kx5eHvv27jm82sw/evp+OzwZ6i0B3cj+Tsv7oJXb8yAXCbgk52ncf/yXbA6mm6iExEREVFLwPDZCIIgoF98Pzx54ZP4/qbv8fJlL+Pi1IshE2TYVbAL87fMx5iPx+CJn57AttxtECWxQce9fkhHLL51CFQKGdbvy8eMZTtQaXM287chIiIiCh2Gz/OklqtxZfqVeGvcW1h//XrMGTwH6ZHpsDgt+N+x/+Gu9Xfhqk+vwhvZb+CU8dQ5j3d53yS8O2MY9Co5th4rxrS3f0GJyR6Cb0JERETU/Bg+m1CSPgl/7v9nfDn5S3ww4QPc2PNGRCgjcNZ0Fov3LMaEzyZgxroZ+OLIFzA76r6J/chu8fjw7gsRo1Niz+ly3PTvrcgtt4TwmxARERE1D4bPZiAIAjISMjAvcx6+v+l7vHjJi8jskAkBAn7N/xVPbn4Soz4ahac2P4Vf834NeHulAR2j8fG9megQpcGRgkrc8NZWHC8yheHbEBERETUdhs9mplFoMKHrBCy5YgnW37AeDw56EJ0MnWBxWrD6yGrM+GYGJnw2AYv3LMbZyrN++3ZPNODjezPRJV6PM2UW3Lh4C/44Wx6mb0JERER0/hg+QyhZn4yZA2biq2u/wvtXvY/relwHnUKH05Wn8Ub2G7jy0ytx1/q78L+j/4PF6e5m7xijw8f3ZqJvh0gUVdpxy79/wY4TJWH+JkRERESNw/AZBoIgYFDiIDwz8hl8f9P3eP7i5zEieQQkSNiWuw1P/PwERn80Gk9veRrZBdmI06uw8p4LMTw9FkabE7e9sw3fHygI99cgIiIiChrDZ5jplDpM7DYR/xn/H6y7fh3uH3g/UiNSYXKY8OnhT3Hb17dh4uqJWHXoXbx0S2eM6Z0Iq0PEzPd/xRfZZ8JdfSIiIqKgMHy2IKkRqbgv4z6svW4tlo5fikndJkGr0OJkxUn8c/c/8acvroQ85W1c2D8HTsmOOauy8d9fToa72kREREQNxsdrtkAyQYZhycMwLHkYnhjxBNafXI/VR1ZjZ/5O/JK7FcBWxPbWwVTaH/PX5aDMNBazx/SAIAjhrjoRERFRvRg+WzidUofJ3SdjcvfJOFVxCl8c/QJfHv0SuaZcqGK2QRWzDW8d/QS/lIzDwgl3IkmfFO4qExEREdWJ3e6tSFpkGmYPmo1116/Df674D67peg0UggpydQF+M6/AuE8ux30b7sc3J76B3cWnIhEREVHLw5bPVkgmyDCiwwiM6DACfx3xVzz/w0qsPvIF5LoT+PnsT/j57E+IVEViQpcJmNx9MvrG9WWXPBEREbUIDJ+tXIQqAs9ffhcuS7kGD368HpLhV+jjdqPCXoaVB1di5cGV6B7dHZO7T8bVXa9GvDY+3FUmIiKidozd7m3E+H7JWHbrBCjLJ6D0wKNINj+AcWnjoZKpcKTsCF759RWM+3gcHtj4ADae3AiHyxHuKhMREVE7xJbPNmRk93ismHkh7li2HYdPpgKWXlh122PYVfI9vjjyBX4r+g2bTm/CptObEKOOwdVdr8ak7pPQO7Z3uKtORERE7QRbPtuYjLRofHRPJpIjNThcUInp7+zFsLirsfzq5fhi0heYccEMJGgTUGorxQf7P8CN/7sRN/7vRnyw7wOUWPnYTiIiImpeDJ9tUI8kAz65LxNd4vU4U2bBjYu3Yt/ZCnSN7oqsIVlYf8N6vDH2DVzR+QooZUocKDmAF3e8iLEfj8VD3z2Ejw5+hIMlB+ESXeH+KkRERNTGsNu9jeoYo8NH92Ri+tLt2JdbgZuXbMWyO4ZhaHosFDIFLu14KS7teCnKrGX4+sTX+OLIF/ij+A98d+o7fHfqOwCAXqlH//j+yEjIwMDEgRiQMACRqsgwfzMiIiJqzRg+27AEgxof3n0h7npvB3acKMWt72zDW7cOweheid4y0ZpoTOk9BVN6T8Gh0kPYcHIDsguysbdoL0wOE37J/QW/5P7iLd8tqhsyEjMwMGEgMhIykB6VDpnABnQiIiJqGIbPNi5Kq8T7d47Afct3YtPBQsx871csvHkg/pSRUqtsz5ie6BnTEwDgEl04UnYEewr3YE/hHmQXZCPHmIOj5UdxtPwoPjv8GQAgUhWJjIQMb+to//j+0Cl1If2ORERE1Ho0Kny+8cYbePnll5GXl4eMjAz861//wvDhw8+538qVKzFlyhRMmjQJq1evbsypqRG0KjmW3DYUj3y8B1/uOYuHVu5GhcWBWy/sXOc+cpkcvWJ7oVdsL9zU6yYAQIm1BHsKPGG0MBt/FP2BCnsFfjrzE3468xMA9w3we8b09AukHSM68ib3REREBKAR4XPVqlXIysrC4sWLMWLECCxatAjjx4/HwYMHkZiYWOd+J06cwCOPPIJLLrnkvCpMjaNSyLDo5oGI0irx319O4snVv6Pc4sD9o7o1OBjGamIxutNojO40GgDgEB04VHII2YXZ3lB61nQWB0oO4EDJAaw6uMq738CEgd7u+r5xfaFRaJrtuxIREVHLFXT4XLhwIWbOnIkZM2YAABYvXow1a9Zg6dKlePzxxwPu43K5MG3aNDzzzDP46aefUFZWdl6VpsaRyQT8bVI/ROuU+Nd3R/DyNwdRZrbjiQl9GtUyqZQp0S++H/rF98O0PtMAAPmm/Oqu+sJs7C/ejxJrid9EJoVMgT6xfdyto55AmqxPbtLvSkRERC1TUOHTbrdj586dmDt3rnedTCbDuHHjsHXr1jr3+9vf/obExET8+c9/xk8//XTO89hsNthsNu9yRUUFAMDhcMDhaP4n81SdIxTnCocHR3eFQS3H818fxNs/HUepyY5n/9QHCvn5TxyKVcVidOpojE51t47aXDYcKDmA34p+w56iPfit8DcUWYuwt2gv9hbtxQf7PwAAJOmSMCB+AAbED0BGfAZ6xfSCUq487/o0VFu/5lQbr3n7xOve/vCah05Df8aCJElSQw969uxZpKamYsuWLcjMzPSuf/TRR/HDDz9g27Zttfb5+eefccsttyA7Oxvx8fG44447UFZWVu+Yz6effhrPPPNMrfUrVqyATsfJLE3llwIBK4/KIEHAgFgR03uIUDTzxHVJklAmliHHlYNTzlPIceUgz5UHEaJfOQUUSJWnIk2Rhk7yTuik6IQIWUTzVo6IiIgazWw2Y+rUqSgvL0dkZN23ZmzW2e5GoxG33XYb3n77bcTHxzd4v7lz5yIrK8u7XFFRgbS0NFxxxRX1fpmm4nA4sGHDBlx++eVQKkPX+hZqEwBcvC8fcz76Db+VyPBpYTzenDoQenVob4JgcVrwR/Ef7tbRwj3YW7wXZbYynHSdxEnXSW+5jhEdq1tHEzLQLaobFLKmqWt7ueZUjde8feJ1b394zUOnqqf6XIL6yx0fHw+5XI78/Hy/9fn5+UhOrj1m7+jRozhx4gQmTpzoXSeK7hYuhUKBgwcPolu3brX2U6vVUKvVtdYrlcqQ/uKE+nzhcHVGR0TrNZj5/q/YcqwE09/bhSev7oP+qVHQKOUhqYNSqURmx0xkdnS3pkuShJMVJ73jRrMLsnG07ChOV57G6crTWHtiLQBAq9C6w2jCAAxMdN93NEoddd51aevXnPzxmrdPvO7tD69582vozzeo8KlSqTBkyBBs3LgRkydPBuAOkxs3bsTs2bNrle/duzf27t3rt+7JJ5+E0WjEa6+9hrS0tGBOT83kou7xWDHzQtyxbDv2nCrDjYu3QikX0LdDJAZ1isHgzjEY0jkGKVGakNwySRAEpEelIz0qHZO6TwIAGO1G7C3c6w2kvxX+hkpHJbblbcO2vOrhHl2iunhvgD8wcSC6RHXhTfCJiIhakKD7LLOysjB9+nQMHToUw4cPx6JFi2Aymbyz32+//XakpqZiwYIF0Gg0uOCCC/z2j46OBoBa6ym8BqZF45N7M7FwwyHsOFGKQqMNe06XY8/pcry75QQAIClSjcGdYtyvztHolxK61lGDyoCRqSMxMnUkAECURBwtO+q9Af6ewj04UXECx8uP43j5cXx+5HPvfgMS3N30AxPcN8GPUHHsKBERUbgEHT5vvvlmFBYWYt68ecjLy8PAgQOxbt06JCUlAQBycnIgk7GlqTXqnmjAm9OGQJIknC61YFdOKXadLMWunDLsy61AfoUNX/+eh69/zwMAqOQy9EuN9AukHaK0IamrTJChR0wP9IjpgRt63gAAKLOW4bei35BdkI3swmz8XvQ7jHYjNp/ZjM1nNgMABAjoEdPD2zI6MGEg0gxsgSciIgqVoGa7h0tFRQWioqLOOXuqqTgcDqxduxYTJkzg+BAPi92F306XYVdOmTeUFpvstcp1iNJgcKcYDOoUjSGdY9AvJQqq5p5CXwen6MSh0kN+raNnKs/UKhejjsGA+AGQF8txScYlSDGkIEmfhCRdEltJ2zD+d94+8bq3P7zmodPQvMZnu1ODaFVyjOgahxFd4wC4JwXllJg9QdQdSA/kGZFbbsWavblYszcXgPvJSv1TozC4U7SndTQGSZGhebqRQqZA37i+6BvXF1N6TwEAFFmKsKfAPW50T+Ee/FH0B0ptpfjhzA8AgO+2fed3DJ1C5w2iibpEJOmSkKxP9n5O0ichRh3Dx4e2ImaHGcXWYhRUFuCI4wiOlR9Dekw61PLakxyJiKjpMXxSowiCgM5xenSO0+PaQR0BACabE7+dLvfpri9FqdmBnSdLsfNkKYDjAIDUaC0Gd47xBtK+KZFQNsEN7hsiXhuPsZ3HYmznsQAAu8uOAyUHsDN3J3744weo49QosBSgwFyACnsFzE6zdxxpXZQyZXUY9QRS33CapEtCvDa+yW4LRf4kSUKFvQLFlmIUWz0vSzFKrCXedVWfS6wlsDgtfvu/u+ZdAECiLhFphjR0jOjofjdUv/MfGERETYd/DanJ6NUKZHaLQ2a36tbRE8VmbxDdebIUh/KNOFNmwZkyC/635ywAQK2QYUDHKG/L6OBOMUgwhKYVSiVXYUDCAPSJ7oPY47GYMLq6W8bsMKPA7A6i+eZ898uU7/1cYC5AsaUYDtGBM5VnAnbpV5EJMsRr4t2h1Lcl1fO5apnPvHdzik6UWksDBsiqgFliqQ6UTskZ1PHVcjViNbFwWVyolFXC7Ky+1jvzd9Yqr1fqa4dSz3JyRDKUMnblERE1FMMnNRtBENAlXo8u8XpcP8TdOlppc2LPqTJvIN19qgxlZgd2nCjFjhOl3n3TYrXVE5k6xaB3B0PIWker6JQ67y2f6uJwOVBoKUSBuQB55jzkm/K9YbXAXOBddkpOd4uqpQC/F/9e5/Gi1dHeVtOqcJqs8+/mj1BGtMpWOKvTWh0afVsnA7RUltnKgj6+QWlAnDYOsZpYv/c4jefls06n0MHpdGLt2rW46qqrUClW4rTxNE4ZT1W/V7rfC8wFMDlMOFh6EAdLD9Y6r1yQI1mfXCuUVi0bVIYm+OkREbUdDJ8UUhFqBS7qHo+LurufeCVJEo4VmbDzZCl2e8aPHiow4lSJBadKLPgi2906qlXK3a2jnasCaTTiIsI/Rk8pVyIlIgUpESl1lhElESXWEm/Lqbcl1fezOR8WpwVltjKU2cpwqPRQncfTKrR+Xfq+LadV62I0Mc1+f1NJkmB0GOvt4vZdZ3KYgjq+TJAhWh1dHRp9A6Tns+86lVzVqO8hCAJiNbGI1cRiQMKAWtttLhvOGM94w6hvSD1dedq93dPyvS239iOGo9RRSIvw78avCqmJukTIZaG5XRkRUUvB8ElhJQgCuiVEoFtCBG4a6r7lUYXV4Wkd9cyszymF0erEtuMl2Ha8xLtv5zidN4gO7hyDXkkGKELcOtoQMkGGeG084rXx6BfXL2CZqiBX1a1f1Wrq7e73hNUKewUsTgtOVJzAiYoTdZ5TIVP4TZIK1M0fr4uv1V3sEl0otdXo7q6npdIhOoL6WShlSm9o9G2Z9H72CZfR6ugWEczUcjW6RndF1+iutbaJkogiS1HAFtPTxtMosZag3FaOclt5wBZvpUyJ1IhUpBpSawXUjhEdoVPqQvEViYhCiuGTWpxIjRKX9EjAJT0SAACiKOFoYaXfzPrDBZU4WWzGyWIzPt/tHmupU8mR0TEagztHe273FINYfeNaw0JNEAREqiIRqYpEj5gedZazOC21gqnvcoG5AEWWIjhF5znHoQoQEK+NR4IuAXaXHSXWEpRaSyEhuLuv6ZX62mFSG7ilsrUOGaiLTJAhUZeIRF0ihiQNqbXd5DC5W0g9raS+IfVs5Vk4REe9/5CI08TVmvyUZkhDmiENcZq4NvWzJKL2g+GTWjyZTECPJAN6JBlw87BOAIByswO7T7lvgL87pxTZOWUw2pzYeqwYW48Ve/ftGq/3PCLUHUh7Jhkgl7XeP9hahRadIzujc2TnOss4RAeKzEV+Laa+3ftVn52iE4WWQhRaCv32FyDU3d1do6UyVhPLSVL10Cv16BXbC71ie9Xa5hSdyDfn1znW1Gg3eidXZRdm19pfq9AiNSLVrxu/6nNqRGqjhyEQETU3hk9qlaJ0SozqlYhRvRIBAC5RwpGCSu9tnnbmlOJYoQnHityvT3edBuAec5qR5jOzPi0GUbq2NVNZKVOiQ0QHdIjoUGeZqnGoVTO8VTKVt9s7Wh3N20KFgEKmcHe5R6RiRIcRtbaX28rdgbTylLf1tCqk5pnzYHFacKTsCI6UHam1rwABSfqkOmfoR6mj2GpKRGHDvzDUJshlAnolG9Ar2YApw92to2VmO3bnVI8bzc4pQ6XNic1HirH5SHXraLcEPQamRUFWKiDqaDG6J0WiQ5S2VbeQnovvONS+cX3DXR0KIEodhSh1FPrF1x4n7HA5cNZ0ttYEqKqganFakGfKQ54pD7/m/1pr/whlBFIjUpGsT/a+qh6g0EHfAUm6JCjlbesfZUTUcjB8UpsVrVNhdO9EjO5d3Tp6KN/ovefo7pwyHC8y4Wih+wXI8fFx9z0eVXIZ0mK1SPfcSL9LvA6d4/RIj9MjJVrTIic2UfuhlCvrHH4hSRKKrcV+3fi+LaeFlkJUOirrvHUU4G45jdPGIVmX7B9QPbf+StYnI0Gb0CImhBFR68PwSe2GXCagT4dI9OkQiWkj3H+0S0x27M4pxa/Hi/Hj3qOwyA04XWqB3SX6hFJ/CpmAtFgdOsfpkB6nR3qcDp3j3cG0Y4w25PcjJfIlCIK3VXtg4sBa2y1OC84Yz+Cs6ay3dTTPlIc8s/s935QPu2hHkaUIRZaiOu9LKxfkSNQluoOpziecVoVVXTJiNbHs3ieiWhg+qV2L1aswtk8SLu0ei96Ow5gw4SLI5AqcLbPgZLEZJ4pNOFlswolis/fd7hRxvMiE40UmAP6TdeQyAR1jtJ5WUp33PT1ej7QYHVQKBlMKL61Ci+4x3dE9pnvA7ZIkocRa4g2jVYG0KqDmmnJRaC6ES3Ih15SLXFNunedSy9Xe7nzfrn3fl0FpYEAlamcYPolqkHtaNtNidbi4R7zfNlGUkFdh9YRSM04Umao/F5tgdYjeW0D9WOO4MgFIia7qytehS7zeG07TYnXQKNmFSeEnCIJ38lld96V1iS4UWgq9gdQbTn1aUYssRbC5bMgx5iDHmFPn+fRKvV/3vm/XftVLq9A219clojBg+CQKgkwmICVai5RoLUZ2898mSRIKjDZvIPW2lha5g6nZ7sLpUgtOl1rwc40JyoIApERp0dmntdQ91lSPTrE6aFUMptRyyGVybzCsi8PlQL45H7mmXHfrqbl2QC23lcPkMOFo+VEcLT9a57Gi1dHervyaXftVLaqcIEXUejB8EjURQRCQFKlBUqQGI7rG+W2TJAmFlTZva2lVS+kJTzittDlxpsyCM2UWbDlaXOvYyZGa6jGm8dXhtHOcDno1/zOmlkcpV7qf1GToWGcZs8McMJT6LpudZu9jZw+UHAh4nKoJUh30HQJ37+uSEa+N5wQpohaCf7WIQkAQBCQaNEg0aDAsPdZvmyRJKDHZfVpKq1tNjxeZUGF1Iq/CirwKq9/jRaskGNTucaWeYFoVUjvH6WDQsDWIWi6dUocuUV3QJapLwO1Vj531C6eeVlRvi2qNCVJ7i/YGPJZCUCBBl4AkXRKMlUZ89d1XUMgVkAkyyCBzvwsyCIIAuSCHIAiQCTL3Zwje7TVfAtzlA+1b89h17et3rnr2rTp+oH1rvQLsK0P1mPOaTzLzXZakup9yVms/n7L1HbPmg9PqO5/ftnrO19B6OZ1OnHaextGyozBoDdApdNAqtFDL1RxvHCYMn0RhJggC4iLUiItQY0jnmFrby8x2HPdpLfW2mhaZUGp2oNBoQ6HRhh0nSmvtGx+h8raQ1hxrGqVlMKWWzfexsz1jegYsc64JUnmmPBSYC+CUnH4TpI7m1d3NT23T4rWL/ZZlggxahdYbRrUKLXRK3TnXVS3XVV6r0LKV/RwYPolauGidCoM6qTCoU+1gWm524GSJp6W0yITjnnB6stiEokq797XzZO1gGqNTeseXdozRoUO0xj2eNUqLDtEaRLLVlFqBYCdI5RpzsX3XdgzIGACZTAZREt0viBBFz7tU/ZIkCS7JBQkSREl0f5YkvzK++1aVD7RvoJcECS7R5bev3/HrqI9330D1qWff+lr6BFRvq1nObxtqHEMIXK7mcWptq+d8japXHdtESURFZQWgct9qzOayedebHCaYHLVvqXe+1HL1eQXYusorZco20VrL8EnUikXplBigi8aAjtG1thmtDv/WUp/W0wKjDaVmB0rNZcg+VRbw2BFqBVKiNegQpfW+d4jSIDVaiw7R7s+coU+tge8EqX4x/WD/3Y4JXSZAqeQ/sNoDh8OBtWvXYsIE9zV3iS5YXVaYHWZYnBaYnZ53z7Lv54Db6lknSiIAwOayweayodRW+x/+50MuyAMGWK2yRnhV6Lzresf2DvgI33Bi+CRqowwaJS5IjcIFqVG1tplsTm8L6YliM86UmZFbZsXZcityyy0oMztQaXPiUH4lDuVX1nmOWL0KHaKqWkw13lBaFVCTDGo+DYqIWhS5TA69TA+9Ut+kx5UkCTaXrTqMOgKH1arlYEKuQ3QAAFySC0aHEUaHEbA0rF4397qZ4ZOIwk+vVqBvSiT6pkQG3G62O3G2zB1E3aHUgrNlFuSWW73vZrsLJSY7Skx2/HG2IuBxZAKQaND4dOlXt6SmRGvRIUqLOL0KMlnr70YiovZNEARoFBpoFBrEoPYwqfPhFJ1Bt8hWLfeP79+kdWkKDJ9EVItOpUD3xAh0T4wIuF2SJFRY3LeHyi23uFtMPaG0al1euRUOl+Sdqb87pyzgsVRyGZKjND4tpv5d/SnRWkRqFG1inBMRUWMoZAoYVAYYVIZwV6VJMHwSUdAEQUCUTokonbLO1lNRlFBksrlbUMsCB9QCow12l4icEjNySsx1nk+vkvt36XsmRaX4vPNG/ERErQPDJxE1C5ms+t6mA9OiA5ZxuETkV1i93flVXf1ny6q69y0oNTtgsrtwpKASRwrqHn8ao1PWajH1nSiVHKWBkuNPiYjCjuGTiMJGKZehY4z7Vk91sdhd7rGnVS2mVQHV05J6tswCk93lmb3vwL7cwONPBQFINKi9ATXJoEbpWQHS3jx0iNYhMVKDRIOaT4wiImpm/L8sEbVoWpUcXRMi0DWhnvGnVmftyVGez7nlVuSWWWF3icivsCG/wobsU1V7y7H65G9+x9Or5EiM1CDBoEaiQe1uvY2s/TlK2zbut0dEFGoMn0TUqgmCgCitElFaJXon1z3+tNhk93bp55ZbcLrEhF0HjkNhiENRpR0FFVaY7C6Y7C4cL3I/2rQ+KoXME0hrB9QEn8+czU9E5I/hk4jaPJlMQIJBjQSDGgM6utc5HA6sFY9iwoRh3puNm2xOFBhtKKiwosBoQ36FFYVGm3ud0YqCCvfncosDdqeI06UWnC6t/2Z7cpmA+AiVZ/yrGomRaiRUfTaokRTpDq7xEWqOSSWidoHhk4jIQ69WoItagS7x9d982upweUNpodHqCayegOr9bEOxyQaXKHm7++sjCECsTuXu7o/U+LSq+i67gyqfLEVErRnDJxFRkDRKOdJidUiLrXuiFAA4XaK7S9+n1dQ3oFYF10KjDU7P0IBikx0H8oz1HtegUXjDaFJkdThNqDEEIELN+6MSUcvD8ElE1EwUnhvoJ0dp6i0nihJKzXZPOK3u9ve++3T725wijFYnjFYnjhbWPy5Vq5T7j0X1dPtXfY7VqRAboUKsTsX7pBJRyDB8EhGFmUwmIC5CjbgINfp0qLtc1cz+wpotqTVaVQsrbDDanLA4XDhZbMbJ4rpv4F9Fo5QhTq9GjF6JGJ0KcXoVYvTV77E6FWL17leMXoUYnQpyTqQiokZg+CQiaiV8Z/Z3T6z/MXtmu7POgFpotKGo0o5Skx0lJjvsLhFWh4gzZRacKat/AlV1XYAordIbSusLqlXr9So5hwEQEcMnEVFbpFMpkB6vQPo5Jk9JkgST3YWSSjtKzO5AWmzyBFOz3bu+xGddmdkBSQLKzA6UmR04do7bUlVRKWSI1dUMqkrE6tWI1Svdy1UvTzneAYCo7WH4JCJqxwRBQIRagQi1Ap3i6p9AVcXpElFmcfgFVb/A6mlRLfWE12KTHTanCLtTRF6FFXkV1gbXz6BR1Nmi6htSq8pEajjJiqilY/gkIqKgKOQyxEe4703ao4H7mO1OT+upA8UmmzuYmhwoMdlQYnJ4hwB4W1nNdkgSvJOrTjRg3CoAKGRCgKDqaV3VKRGpkeNwmYBOZyoQH6lFtE7JuwIQhRjDJxERNTudSgGdSoGOMQ0r7xIlVFgc7hZVn9ZUb/d/zVZWkx0muwtOUUKh5/ZVdZPjrf2/eJcUMgHROiWidSrE6JSI0rrfq9epPJ+ViNaqvJOyeL9VosZh+CQiohZH7mnBjNGrGryP1eGqFVRLagwHKK60ISe/BKJcg1LPk6qcooSiSjuKKu1B1VGtkPkF0+rPKkRr/ZdjPO9RWiVUCo5jpfaN4ZOIiNoEjVKODlFadIjS1lnG4XBg7dq1mDDhMiiVSljsLpRZ3MMBysx291hWz6SqMrMdpZ5JVe7PdpRb3MtOUYKtEWNYASBCrUCUVultQY0KGFT9Q2ykVslbW1GbwfBJRETtllYlh1ZVf2CtSZIkVNqcKDNXB9WqYFpq8vnsCa/lnvcKq/suAZU2Jyptzgbf1gpw39oqUqN0DwvwBNTawbX6c9U7x7NSS8TwSUREFARBEGDQKGHQKM/5iFVfVeNYSz0trGXe4Or72dPq6mmNLbc4UGlzQpKAcot7GQ2cfAVUj2eN0rpbUiM1Chg0SkRqFZ7voEBk1btWiUjvsnudjvdmpWbA8ElERBQCjRnHCgB2p4gyix3lgYKqJ8SWmtyBtereq6Vm9+2t/MezNux+rDXr7BtQDT7htCrARtYIsP7lOcaVamP4JCIiasFUChkSDRokGjRB7ec3ntUTTI1WB4xWJyqsTlRYHJ5bWbmHBLjXO7y3t3KJElyi5A20jaVRyrwh1RCwldWnNVatrA6wnvcIlQIyjndtUxg+iYiI2qDGjGetIkkSzHaXTyB1+AXW6pDqQIXF6d3uDbcWB0x2FwDA6hBhdZzr9ld1EwT3JK3IAMMEaray+rbGVr1rFYAkNerU1EwYPomIiMiPIAjQqxXQqxVIjgquxbWK0yWi0ub0htWqkOobXr2tr7baIbbC4oTdJfo9bKCx5IIcf9v7PSI1ysChtY5AG+kJtBFqBRR81GuTYfgkIiKiJqeQy9y3i9IFN8bVl9XhqqeltXqIQIXFJ7R6y7kna4kS4JIEzxO1Gj98QK+SB2xdDRhaOXmrXgyfRERE1CJplHJolHIkGNSN2l+SJJRWWvHl1+sxbOQlMDtRa6hAzVbYmssWh3v4gMnugsnuQl5F475LzclbdQ0XiPRbrp7o1ZYmbzF8EhERUZvkvi2WAjFqoGeSAUqlMuhjOFxiwFZX/0lbPmNjLf7DCIxWJ5xNOHnLf4iAz/CAOlpgO0Rp0DGm4bcECwWGTyIiIqI6KOUyxOpViA3yFllVJEmCpWr4gCVwa6vfHQcCtMDWnLxVEMTkrSnD07DgugGNqntzYfgkIiIiaiaCIECnUkCnUiApsnGTt1yihMqqiVv13GHAL7R63htzt4Pm1mbCpyiKsNvtTXIsh8MBhUIBq9UKl8vVJMeklkGlUkEmaxtjZoiIqH2QywRE6ZSI0gU/bKAlahPh02634/jx4xBFsUmOJ0kSkpOTcerUKc5Ma2NkMhm6dOkClarxsy+JiIio8Vp9+JQkCbm5uZDL5UhLS2uSVi1RFFFZWYmIiAi2krUhoiji7NmzyM3NRadOnfgPCyIiojBo9eHT6XTCbDYjJSUFOl3TzOaq6sLXaDQMn21MQkICzp49C6fT2ahZj0RERHR+Wn2yqhqTyW5Uaoiq3xOO5SUiIgqPVh8+q7ALlRqCvydERETh1WbCJxERERG1fAyfYTJq1CjMmTMn3NUgIiIiCimGTyIiIiIKGYZPIiIiIgoZhs8WoLS0FLfffjtiYmKg0+lw1VVX4fDhw97tJ0+exMSJExETEwO9Xo9+/fph7dq13n2nTZuGhIQEaLVa9OjRA8uWLQvXVyEiIiKqV6u/z2dNkiTB4ji/2+iIogiL3QWF3RnUfT61SnmjZlPfcccdOHz4ML788ktERkbisccew4QJE7Bv3z4olUrMmjULdrsdP/74I/R6Pfbt24eIiAgAwFNPPYV9+/bh66+/Rnx8PI4cOQKLxRJ0HYiIiIhCoc2FT4vDhb7zvgnLuff9bTx0quB+pFWhc/PmzRg5ciQAYPny5UhLS8Pq1atx4403IicnB9dffz369+8PAOjatat3/5ycHAwaNAhDhw4FAKSnpzfNlyEiIiJqBux2D7P9+/dDoVBgxIgR3nVxcXHo1asX9u/fDwB48MEH8fe//x0XXXQR5s+fj99++81b9r777sPKlSsxcOBAPProo9iyZUvIvwMRERFRQ7W5lk+tUo59fxt/XscQRRHGCiMMkYagu92bw1133YXx48djzZo1WL9+PRYsWIBXX30VDzzwAK666iqcPHkSa9euxYYNGzB27FjMmjULr7zySrPUhYiIiOh8NKrl84033kB6ejo0Gg1GjBiB7du311n27bffxiWXXIKYmBjExMRg3Lhx9ZY/X4IgQKdSnPdLq5IHvU9jxnv26dMHTqcT27Zt864rLi7GwYMH0bdvX++6tLQ03Hvvvfjss8/wf//3f3j77be92xISEjB9+nR88MEHWLRoEZYsWXJ+P0QiIiKiZhJ0+Fy1ahWysrIwf/587Nq1CxkZGRg/fjwKCgoClt+0aROmTJmC77//Hlu3bkVaWhquuOIKnDlz5rwr3xb06NEDkyZNwsyZM/Hzzz9jz549uPXWW5GamopJkyYBAObMmYNvvvkGx48fx65du/D999+jT58+AIB58+bhiy++wJEjR/DHH3/gq6++8m4jIiIiammCDp8LFy7EzJkzMWPGDPTt2xeLFy+GTqfD0qVLA5Zfvnw57r//fgwcOBC9e/fGf/7zH4iiiI0bN5535duKZcuWYciQIbjmmmuQmZkJSZKwdu1aKJVKAIDL5cKsWbPQp08fXHnllejZsyfefPNNAIBKpcLcuXMxYMAAXHrppZDL5Vi5cmU4vw4RERFRnYIa82m327Fz507MnTvXu04mk2HcuHHYunVrg45hNpvhcDgQGxtbZxmbzQabzeZdrqioAAA4HA44HA6/sg6HA5IkQRRFiKIYzNepkyRJ3vemOmZN3333HQD3+NKoqCi8++67tcpUnfu1117Da6+9FnD7E088gSeeeKLOfcmfKIqQJAkOhwNyefUY3arfq5q/X9R28Zq3T7zu7Q+veeg09GccVPgsKiqCy+VCUlKS3/qkpCQcOHCgQcd47LHHkJKSgnHjxtVZZsGCBXjmmWdqrV+/fj10Op3fOoVCgeTkZFRWVsJutzeoDg1lNBqb9HgUfna7HRaLBT/++COcTmet7Rs2bAhDrSiceM3bJ1739ofXvPmZzeYGlQvpbPcXXngBK1euxKZNm6DRaOosN3fuXGRlZXmXKyoqvGNFIyMj/cparVacOnUKERER9R4zGJIkwWg0wmAwNGoSEbVcVqsVWq0Wl156qd/vi8PhwIYNG3D55Zd7hztQ28Zr3j7xurc/vOahU9VTfS5Bhc/4+HjI5XLk5+f7rc/Pz0dycnK9+77yyit44YUX8O2332LAgAH1llWr1VCr1bXWK5XKWr84LpcLgiBAJpMFdVuk+lR1WVcdl9oOmUwGQRAC/i4BgX/HqG3jNW+feN3bH17z5tfQn29QyUqlUmHIkCF+k4WqJg9lZmbWud9LL72EZ599FuvWrfM+iYeIiIiI2p+gu92zsrIwffp0DB06FMOHD8eiRYtgMpkwY8YMAMDtt9+O1NRULFiwAADw4osvYt68eVixYgXS09ORl5cHAIiIiPA+n5yIiIiI2oegw+fNN9+MwsJCzJs3D3l5eRg4cCDWrVvnnYSUk5Pj11X91ltvwW6344YbbvA7zvz58/H000+fX+2JiIiIqFVp1ISj2bNnY/bs2QG3bdq0yW/5xIkTjTkFEREREbVBnE1DRERERCHD8ElEREREIcPwSUREREQhw/BJRERERCHD8ElefO4tERERNTeGzzBat24dLr74YkRHRyMuLg7XXHMNjh496t1++vRpTJkyBbGxsdDr9Rg6dCi2bdvm3f6///0Pw4YNg0ajQXx8PK699lrvNkEQsHr1ar/zRUdH49133wXgvguBIAhYtWoVLrvsMmg0GixfvhzFxcWYMmUKUlNTodPp0L9/f3z44Yd+xxFFES+99BK6d+8OtVqNTp064bnnngMAjBkzptadEAoLC6FSqfweTkBERETtU0if7R4SkgQ4GvZg+zqJovsYdjkQzOM1lTogiGfBm0wmZGVlYcCAAaisrMS8efNw7bXXIjs7G2azGZdddhlSU1Px5ZdfIjk5Gbt27fI++nPNmjW49tpr8de//hXvv/8+7HY71q5dG+w3xeOPP45XX30VgwYNgkajgdVqxZAhQ/DYY48hMjISa9aswW233YZu3bph+PDhAIC5c+fi7bffxj/+8Q9cfPHFyM3NxYEDBwAAd911F2bPno1XX33V+4jUDz74AKmpqRgzZkzQ9SMiIqK2pe2FT4cZeD7lvA4hAxDdmB2fOAuo9A0ufv311/stL126FAkJCdi3bx+2bNmCwsJC7NixA7GxsQCA7t27e8s+99xzuOWWW/DMM89412VkZARd5Tlz5uC6667zW/fII494Pz/wwAP45ptv8NFHH2H48OEwGo147bXX8Prrr2P69OkAgG7duuHiiy8GAFx33XWYPXs2vvjiC9x0000AgHfffRd33HEHhCCCOREREbVN7HYPo8OHD2PKlCno2rUrIiMjkZ6eDsD9lKjs7GwMGjTIGzxrys7OxtixY8+7DkOHDvVbdrlcePbZZ9G/f3/ExsYiIiIC33zzDXJycgAA+/fvh81mq/PcGo0Gt912G5YuXQoA2LVrF37//Xfccccd511XIiIiav3aXsunUudugTwPoiiiwmhEpMHg96jQBp07CBMnTkTnzp3x9ttvIyUlBaIo4oILLoDdbodWq61333NtFwQBkiT5rQs0oUiv92+pffnll/Haa69h0aJF6N+/P/R6PebMmQO73d6g8wLurveBAwfi9OnTWLZsGcaMGYPOnTufcz8iIiJq+9pey6cguLu+z/el1AW/TxDdysXFxTh48CCefPJJjB07Fn369EFpaal3+4ABA5CdnY2SkpKA+w8YMKDeCTwJCQnIzc31Lh8+fBhm87nHwm7evBmTJk3CrbfeioyMDHTt2hWHDh3ybu/Rowe0Wm295+7fvz+GDh2Kt99+GytWrMCdd955zvMSERFR+9D2wmcrERMTg7i4OCxZsgRHjhzBd999h6ysLO/2KVOmIDk5GZMnT8bmzZtx7NgxfPrpp9i6dSsAYP78+fjwww8xf/587N+/H3v37sWLL77o3X/MmDF4/fXXsXv3bvz666+49957oVQqz1mvHj16YMOGDdiyZQv279+Pe+65B/n5+d7tGo0Gjz32GB599FG8//77OHr0KH755Re88847fse566678MILL0CSJL9Z+ERERNS+MXyGiUwmw8qVK7Fz505ccMEFePjhh/Hyyy97t6tUKqxfvx6JiYmYMGEC+vfvjxdeeAFyuRwAMGrUKHz88cf48ssvMXDgQIwZMwbbt2/37v/qq68iLS0Nl1xyCaZOnYpHHnkEOt25hwU8+eSTGDx4MMaPH49Ro0Z5A7Cvp556Cv/3f/+HefPmoU+fPrj55ptRUFDgV2bKlClQKBSYMmUKNBrNefykiIiIqC1pe2M+W5Fx48Zh3759fut8x2l27twZn3zySZ37X3fddbVmqldJSUnBN99847eurKzM+zk9Pb3WmFAAiI2NrXV/0JpkMhn++te/4q9//WudZYqKimC1WvHnP/+53mMRERFR+8LwSU3K4XCguLgYTz75JC688EIMHjw43FUiIiKiFoTd7tSkNm/ejA4dOmDHjh1YvHhxuKtDRERELQxbPqlJjRo1KmB3PhERERHAlk8iIiIiCiGGTyIiIiIKGYZPIiIiIgoZhk8iIiIiChmGTyIiIiIKGYZPIiIiIgoZhs9WLD09HYsWLWpQWUEQzvnkIiIiIqLmxvBJRERERCHD8ElEREREIcPwGSZLlixBSkoKRFH0Wz9p0iTceeedOHr0KCZNmoSkpCRERERg2LBh+Pbbb5vs/Hv37sWYMWOg1WoRFxeHu+++G5WVld7tmzZtwvDhw6HX6xEdHY2LLroIJ0+eBADs2bMHo0ePhsFgQGRkJIYMGYJff/21yepGREREbVebC5+SJMHsMJ/3y+K0BL1PMI+VvPHGG1FcXIzvv//eu66kpATr1q3DtGnTUFlZiQkTJmDjxo3YvXs3rrzySkycOBE5OTnn/TMymUwYP348YmJisGPHDnz88cf49ttvMXv2bACA0+nE5MmTcdlll+G3337D1q1bcffdd0MQBADAtGnT0LFjR+zYsQM7d+7E448/DqVSed71IiIioravzT3b3eK0YMSKEWE597ap26BT6hpUNiYmBldddRVWrFiBsWPHAgA++eQTxMfHY/To0ZDJZMjIyPCWf/bZZ/H555/jyy+/9IbExlqxYgWsVivef/996PV6AMDrr7+OiRMn4sUXX4RSqUR5eTmuueYadOvWDQDQp08f7/45OTn4y1/+gt69ewMAevTocV71ISIiovajzbV8tibTpk3Dp59+CpvNBgBYvnw5brnlFshkMlRWVuKRRx5Bnz59EB0djYiICOzfv79JWj7379+PjIwMb/AEgIsuugiiKOLgwYOIjY3FHXfcgfHjx2PixIl47bXXkJub6y2blZWFu+66C+PGjcMLL7yAo0ePnnediIiIqH1ocy2fWoUW26ZuO69jiKIIo9EIg8EAmazh+Vyr0AZ1nokTJ0KSJKxZswbDhg3DTz/9hH/84x8AgEceeQQbNmzAK6+8gu7du0Or1eKGG26A3W4P6hyNtWzZMjz44INYt24dVq1ahSeffBIbNmzAhRdeiKeffhpTp07FmjVr8PXXX2P+/PlYuXIlrr322pDUjYiIiFqvNhc+BUFocNd3XURRhFPhhE6pCyp8Bkuj0eC6667D8uXLceTIEfTq1QuDBw8GAGzevBl33HGHN9BVVlbixIkTTXLePn364N1334XJZPK2fm7evBkymQy9evXylhs0aBAGDRqEuXPnIjMzEytWrMCFF14IAOjZsyd69uyJhx9+GFOmTMGyZcsYPomIiOic2O0eZtOmTcOaNWuwdOlSTJs2zbu+R48e+Oyzz5CdnY09e/Zg6tSptWbGn885NRoNpk+fjt9//x3ff/89HnjgAdx2221ISkrC8ePHMXfuXGzduhUnT57E+vXrcfjwYfTp0wcWiwWzZ8/Gpk2bcPLkSWzevBk7duzwGxNKREREVJc21/LZ2owZMwaxsbE4ePAgpk6d6l2/cOFC3HnnnRg5ciTi4+Px2GOPoaKioknOqdPp8M033+Chhx7CsGHDoNPpcP3112PhwoXe7QcOHMB7772H4uJidOjQAbNmzcI999wDp9OJ4uJi3H777cjPz0d8fDyuu+46PPPMM01SNyIiImrbGD7DTCaT4ezZs7XWp6en47vvvvNbN2vWLL/lYLrha94Gqn///rWOXyUpKQmff/55wG0qlQoffvhhg89LRERE5Ivd7kREREQUMgyfbcDy5csRERER8NWvX79wV4+IiIjIi93ubcCf/vQnjBgR+Mb6fPIQERERtSQMn22AwWCAwWAIdzWIiIiIzond7kREREQUMgyfRERERBQyDJ9EREREFDIMn0REREQUMgyfRERERBQyDJ+tWHp6OhYtWhTuahARERE1GMMnEREREYUMwyeFhcvlgiiK4a4GERERhRjDZ5gsWbIEKSkptQLYpEmTcOedd+Lo0aOYNGkSkpKSEBERgWHDhuHbb79t9PkWLlyI/v37Q6/XIy0tDffffz8qKyv9ymzevBmjRo2CTqdDTEwMxo8fj9LSUgCAKIp46aWX0L17d6jVanTq1AnPPfccAGDTpk0QBAFlZWXeY2VnZ0MQBJw4cQIA8O677yI6Ohpffvkl+vbtC7VajZycHOzYsQOXX3454uPjERUVhcsuuwy7du3yq1dZWRnuueceJCUlQaPR4IILLsBXX30Fk8mEyMhIfPLJJ37lV69eDb1eD6PR2OifFxERETWPNhc+JUmCaDaf/8tiCXofSZIaXM8bb7wRxcXF+P77773rSkpKsG7dOkybNg2VlZWYMGECNm7ciN27d+PKK6/ExIkTkZOT06ifi0wmwz//+U/88ccfeO+99/Ddd9/h0Ucf9W7Pzs7G2LFj0bdvX2zduhU///wzJk6cCJfLBQCYO3cuXnjhBTz11FPYt28fVqxYgaSkpKDqYDab8eKLL+I///kP/vjjDyQmJsJoNGL69On4+eef8csvv6BHjx6YMGGCNziKooirrroKmzdvxgcffIB9+/bhhRdegFwuh16vxy233IJly5b5nWfZsmW44YYb+NQnIiKiFqjNPV5TslhwcPCQJjlWfpDle+3aCUGna1DZmJgYXHXVVVixYgXGjh0LAPjkk08QHx+P0aNHQyaTISMjw1v+2Wefxeeff44vv/wSs2fPDrJmwJw5c7yf09PT8fe//x333nsv3nzzTQDASy+9hKFDh3qXAaBfv34AAKPRiNdeew2vv/46pk+fDgDo1q0bLr744qDq4HA48Oabb/p9rzFjxviVWbJkCaKjo/HDDz/gmmuuwbfffovt27dj//796NmzJwCga9eu3vJ33XUXRo4cidzcXHTo0AEFBQVYu3btebUSExERUfNpcy2frcm0adPw6aefwmazAQCWL1+OW265BTKZDJWVlXjkkUfQp08fREdHIyIiAvv37290y+e3336LsWPHIjU1FQaDAbfddhuKi4thNpsBVLd8BrJ//37YbLY6tzeUSqXCgAED/Nbl5+dj5syZ6NGjB6KiohAZGYnKykrv98zOzkbHjh29wbOm4cOHo1+/fnjvvfcAAB988AE6d+6MSy+99LzqSkRERM2jzbV8Cloteu3aeV7HEEURFUYjIg0GyGQNz+eCVhvUeSZOnAhJkrBmzRoMGzYMP/30E/7xj38AAB555BFs2LABr7zyCrp37w6tVosbbrgBdrs9qHMAwIkTJ3DNNdfgvvvuw3PPPYfY2Fj8/PPP+POf/wy73Q6dTgdtPXWvbxsA78/Id9iBw+EIeBxBEPzWTZ8+HcXFxXjttdfQuXNnqNVqZGZmer/nuc4NuFs/33jjDTz++ONYtmwZZsyYUes8RERE1DK0uZZPQRAg0+nO/6XVBr1PsIFHo9Hguuuuw/Lly/Hhhx+iV69eGDx4MAD35J877rgD1157Lfr374/k5GTv5J1g7dy5E6Io4tVXX8WFF16Inj174uzZs35lBgwYgI0bNwbcv0ePHtBqtXVuT0hIAADk5uZ612VnZzeobps3b8aDDz6ICRMmoF+/flCr1SgqKvKr1+nTp3Ho0KE6j3Hrrbfi5MmT+Oc//4l9+/Z5hwYQERFRy9PmwmdrM23aNKxZswZLly7FtGnTvOt79OiBzz77DNnZ2dizZw+mTp3a6FsTde/eHQ6HA//6179w7Ngx/Pe//8XixYv9ysydOxc7duzA/fffj99++w0HDhzAW2+9haKiImg0Gjz22GN49NFH8f777+Po0aP45Zdf8M4773iPn5aWhqeffhqHDx/GmjVr8Oqrrzaobj169MB///tf7N+/H9u2bcO0adP8Wjsvu+wyXHrppbj++uuxYcMGHD9+HF9//TXWrVvnLRMTE4PrrrsOf/nLX3DFFVegY8eOjfo5ERERUfNj+AyzMWPGIDY2FgcPHsTUqVO96xcuXIiYmBiMHDkSEydOxPjx472tosHKyMjAwoUL8eKLL+KCCy7A8uXLsWDBAr8yPXv2xPr167Fnzx4MHz4cmZmZ+OKLL6BQuEdmPPXUU/i///s/zJs3D3369MHNN9+MgoICAIBSqcSHH36IAwcOYMCAAXjxxRfx97//vUF1e+edd1BaWorBgwfjtttuw4MPPojExES/Mp9++imGDRuGKVOmoG/fvnj00Ue9s/CrVA0huPPOOxv1MyIiIqLQEKRg7g8UJhUVFYiKikJ5eTkiIyP9tlmtVhw/fhxdunSBRqNpkvOJooiKigpERkYGNeaTwue///0vHn74YZw9exYqlarOcnX9vjgcDqxduxYTJkyAUqkMRZUpzHjN2yde9/aH1zx06strvtrchCNqX8xmM3Jzc/HCCy/gnnvuqTd4EhERUfixWa8NWL58OSIiIgK+qu7V2Va99NJL6N27N5KTkzF37txwV4eIiIjOgS2fbcCf/vQnjBgxIuC2tt7F8PTTT+Ppp58OdzWIiIiogRg+2wCDwcBHSRIREVGrwG53IiIiIgqZNhM+W8GkfWoB+HtCREQUXq2+212pVEIQBBQWFiIhIaFJHqsoiiLsdjusVitvtdSGSJKEwsJCCILQ5sfCEhERtVStPnzK5XJ07NgRp0+fbvTjJ2uSJAkWiyXgs8ipdRMEAR07doRcLg93VYiIiNqlVh8+ASAiIgI9evSAw+FokuM5HA78+OOPuPTSS9lC1sYolUoGTyIiojBqE+ETcLeANlWokMvlcDqd0Gg0DJ9ERERETahRAxrfeOMNpKenQ6PRYMSIEdi+fXu95T/++GP07t0bGo0G/fv3x9q1axtVWSIiIiJq3YIOn6tWrUJWVhbmz5+PXbt2ISMjA+PHj0dBQUHA8lu2bMGUKVPw5z//Gbt378bkyZMxefJk/P777+ddeSIiIiJqXYIOnwsXLsTMmTMxY8YM9O3bF4sXL4ZOp8PSpUsDln/ttddw5ZVX4i9/+Qv69OmDZ599FoMHD8brr79+3pUnIiIiotYlqDGfdrsdO3fu9HuGtkwmw7hx47B169aA+2zduhVZWVl+68aPH4/Vq1fXeR6bzQabzeZdLi8vBwCUlJQ02aSi+jgcDpjNZhQXF3PMZzvBa97+8Jq3T7zu7Q+veegYjUYA576ndlDhs6ioCC6XC0lJSX7rk5KScODAgYD75OXlBSyfl5dX53kWLFiAZ555ptb6Ll26BFNdIiIiIgoxo9GIqKioOre3yNnuc+fO9WstFUURJSUliIuLC8l9NysqKpCWloZTp04hMjKy2c9H4cdr3v7wmrdPvO7tD6956EiSBKPRiJSUlHrLBRU+4+PjIZfLkZ+f77c+Pz8fycnJAfdJTk4OqjwAqNVqqNVqv3XR0dHBVLVJREZG8he1neE1b394zdsnXvf2h9c8NOpr8awS1IQjlUqFIUOGYOPGjd51oihi48aNyMzMDLhPZmamX3kA2LBhQ53liYiIiKjtCrrbPSsrC9OnT8fQoUMxfPhwLFq0CCaTCTNmzAAA3H777UhNTcWCBQsAAA899BAuu+wyvPrqq7j66quxcuVK/Prrr1iyZEnTfhMiIiIiavGCDp8333wzCgsLMW/ePOTl5WHgwIFYt26dd1JRTk4OZLLqBtWRI0dixYoVePLJJ/HEE0+gR48eWL16NS644IKm+xZNTK1WY/78+bW6/qnt4jVvf3jN2yde9/aH17zlEaRzzYcnIiIiImoijXq8JhERERFRYzB8EhEREVHIMHwSERERUcgwfBIRERFRyDB81vDGG28gPT0dGo0GI0aMwPbt28NdJWpGCxYswLBhw2AwGJCYmIjJkyfj4MGD4a4WhdALL7wAQRAwZ86ccFeFmtGZM2dw6623Ii4uDlqtFv3798evv/4a7mpRM3G5XHjqqafQpUsXaLVadOvWDc8+++w5nzlOocHw6WPVqlXIysrC/PnzsWvXLmRkZGD8+PEoKCgId9Womfzwww+YNWsWfvnlF2zYsAEOhwNXXHEFTCZTuKtGIbBjxw78+9//xoABA8JdFWpGpaWluOiii6BUKvH1119j3759ePXVVxETExPuqlEzefHFF/HWW2/h9ddfx/79+/Hiiy/ipZdewr/+9a9wV43AWy35GTFiBIYNG4bXX38dgPvpTWlpaXjggQfw+OOPh7l2FAqFhYVITEzEDz/8gEsvvTTc1aFmVFlZicGDB+PNN9/E3//+dwwcOBCLFi0Kd7WoGTz++OPYvHkzfvrpp3BXhULkmmuuQVJSEt555x3vuuuvvx5arRYffPBBGGtGAFs+vex2O3bu3Ilx48Z518lkMowbNw5bt24NY80olMrLywEAsbGxYa4JNbdZs2bh6quv9vtvntqmL7/8EkOHDsWNN96IxMREDBo0CG+//Xa4q0XNaOTIkdi4cSMOHToEANizZw9+/vlnXHXVVWGuGQGNeMJRW1VUVASXy+V9UlOVpKQkHDhwIEy1olASRRFz5szBRRdd1KKfwEXnb+XKldi1axd27NgR7qpQCBw7dgxvvfUWsrKy8MQTT2DHjh148MEHoVKpMH369HBXj5rB448/joqKCvTu3RtyuRwulwvPPfccpk2bFu6qERg+ibxmzZqF33//HT///HO4q0LN6NSpU3jooYewYcMGaDSacFeHQkAURQwdOhTPP/88AGDQoEH4/fffsXjxYobPNuqjjz7C8uXLsWLFCvTr1w/Z2dmYM2cOUlJSeM1bAIZPj/j4eMjlcuTn5/utz8/PR3JycphqRaEye/ZsfPXVV/jxxx/RsWPHcFeHmtHOnTtRUFCAwYMHe9e5XC78+OOPeP3112Gz2SCXy8NYQ2pqHTp0QN++ff3W9enTB59++mmYakTN7S9/+Qsef/xx3HLLLQCA/v374+TJk1iwYAHDZwvAMZ8eKpUKQ4YMwcaNG73rRFHExo0bkZmZGcaaUXOSJAmzZ8/G559/ju+++w5dunQJd5WomY0dOxZ79+5Fdna29zV06FBMmzYN2dnZDJ5t0EUXXVTrFmqHDh1C586dw1Qjam5msxkymX/EkcvlEEUxTDUiX2z59JGVlYXp06dj6NChGD58OBYtWgSTyYQZM2aEu2rUTGbNmoUVK1bgiy++gMFgQF5eHgAgKioKWq02zLWj5mAwGGqN6dXr9YiLi+NY3zbq4YcfxsiRI/H888/jpptuwvbt27FkyRIsWbIk3FWjZjJx4kQ899xz6NSpE/r164fdu3dj4cKFuPPOO8NdNQJvtVTL66+/jpdffhl5eXkYOHAg/vnPf2LEiBHhrhY1E0EQAq5ftmwZ7rjjjtBWhsJm1KhRvNVSG/fVV19h7ty5OHz4MLp06YKsrCzMnDkz3NWiZmI0GvHUU0/h888/R0FBAVJSUjBlyhTMmzcPKpUq3NVr9xg+iYiIiChkOOaTiIiIiEKG4ZOIiIiIQobhk4iIiIhChuGTiIiIiEKG4ZOIiIiIQobhk4iIiIhChuGTiIiIiEKG4ZOIiIiIQobhk4iIiIhChuGTiIiIiEKG4ZOIiIiIQobhk4iIiIhC5v8BiNvu7ci0R14AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Primero vemos como ha mejorado el modelo durante el entrenamiento\n",
    "pd.DataFrame(adj_model.history).plot(figsize = (8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 288us/step - loss: 0.3290 - accuracy: 0.8810\n",
      "313/313 [==============================] - 0s 665us/step\n",
      "=====================================================================\n",
      "La etiqueta de la imagen es: 4 y el algoritmo lo clasifica como: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x261413ff310>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluamos el modelo según los valores test que nos proporcionan\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "# Podemos probar aleatoriamente uno de las imagenes de los test y ver si se obtienen lo mismo\n",
    "rd = int( np.random.randint(low=0, high=test_images.shape[0]-1, size=1, dtype=int) )\n",
    "\n",
    "# Guardamos la prediccion de la etiqueta\n",
    "tag_pr = model.predict(test_images)[rd].argmax()\n",
    "\n",
    "print(\"=====================================================================\")\n",
    "print(\"La etiqueta de la imagen es: {} y el algoritmo lo clasifica como: {}\".format(test_labels[rd], tag_pr))\n",
    "plt.imshow(test_images[rd], cmap=\"gray\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygMVnmSYO83U"
   },
   "source": [
    "\n",
    "## 3: Funcionamiento de las predicción de la red neuronal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMa-GR0Kvcqh"
   },
   "source": [
    "Ahora vamos a explorar el código con una serie de ejercicios para alcanzar un grado de comprensión mayor sobre las redes neuronales y su entrenamiento.\n",
    "\n",
    "Sigue los siguientes pasos: \n",
    "\n",
    "* Crea una variable llamada **classifications** para construir un clasificador con las imágenes de prueba, para ello puedes utilizar la función predict sobre el conjunto de test\n",
    "* Imprime con la función print la primera entrada en las clasificaciones. \n",
    "\n",
    "**pregunta 3.1 (0.25 puntos)**, el resultado al imprimirlo es un vector de números, \n",
    "* ¿Por qué crees que ocurre esto? ¿Qué representa este vector de números?\n",
    "\n",
    "**pregunta 3.2 (0.25 puntos)**\n",
    "* ¿Cúal es la clase de la primera entrada de la variable **classifications**? La respuesta puede ser un número o su etiqueta/clase equivalente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "b-mL-h4xQhCm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 249us/step\n",
      "[4.7505996e-06 7.1268097e-08 8.3327245e-07 1.1647826e-05 4.5787697e-06 1.3935639e-02 4.7228477e-05 2.2606285e-02 3.6410169e-05 9.6335256e-01] 9\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "print(classifications[0], classifications[0].argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvbVC9gaQhMY"
   },
   "source": [
    "<b>Respuesta a la pregunta 3.1:</b>\n",
    "Lo que nos imprime son las salidas de las neuronas de output. Esto nos indica que valor es más probable que sea con respecto a la clase equivalente por orden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRWo-75tdgv0"
   },
   "source": [
    "<b>Respuesta a la pregunta 3.2:</b>\n",
    "La clase nos la indica la posicion del elemento mayor del array. En este caso, el elemento que mayor valor tiene está localizado en la posición 9, por lo que la clase predicha es la 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiQ8qAzhRQ4L"
   },
   "source": [
    "## 4: Impacto variar el número de neuronas en las capas ocultas\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lsqive4ivMF9"
   },
   "source": [
    "En este ejercicio vamos a experimentar con nuestra red neuronal cambiando el numero de neuronas por 512 y por 1024. Para ello, utiliza la red neuronal de la pregunta 1, y en su capa oculta cambia las 128 neuronas por:\n",
    "\n",
    "* **512 neuronas en la capa oculta\n",
    "* **1024 neuronas en la capa oculta\n",
    "\n",
    "Entrena la red en ambos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "cdP8ZwuaUV93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5026 - accuracy: 0.8225 - val_loss: 0.4537 - val_accuracy: 0.8360\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3852 - accuracy: 0.8586 - val_loss: 0.4157 - val_accuracy: 0.8501\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3414 - accuracy: 0.8746 - val_loss: 0.3613 - val_accuracy: 0.8697\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3151 - accuracy: 0.8837 - val_loss: 0.3554 - val_accuracy: 0.8703\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2925 - accuracy: 0.8906 - val_loss: 0.3470 - val_accuracy: 0.8747\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2757 - accuracy: 0.8975 - val_loss: 0.3335 - val_accuracy: 0.8818\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2590 - accuracy: 0.9032 - val_loss: 0.3344 - val_accuracy: 0.8769\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2464 - accuracy: 0.9074 - val_loss: 0.3343 - val_accuracy: 0.8796\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2340 - accuracy: 0.9112 - val_loss: 0.3312 - val_accuracy: 0.8783\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2226 - accuracy: 0.9167 - val_loss: 0.3271 - val_accuracy: 0.8850\n",
      "============================================================\n",
      "313/313 [==============================] - 0s 681us/step - loss: 0.3271 - accuracy: 0.8850\n",
      "\n",
      "El accuracy de este modelo al evaluarlo es: 0.8849999904632568 \n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Creacion del Modelo\n",
    "###########################################\n",
    "\n",
    "# Creamos el modelo de Red Neuronal secuencial\n",
    "model2 = keras.models.Sequential()\n",
    "\n",
    "# Creamos la capa de entrada\n",
    "model2.add(keras.layers.Flatten(input_shape = sz_image))\n",
    "\n",
    "# Creamos una única capa oculta con 512 neuronas\n",
    "model2.add(keras.layers.Dense(512, activation = fun_hid_layer))\n",
    "\n",
    "# Creamos la capa de salida\n",
    "model2.add(keras.layers.Dense(tags, activation = fun_output_layer))\n",
    "\n",
    "# Modificamos los parámetros del modelo\n",
    "model2.compile(loss=\"sparse_categorical_crossentropy\", optimizer = opt, metrics = metr, steps_per_execution = sz_batch)\n",
    "\n",
    "###########################################\n",
    "# Ajuste del Modelo\n",
    "###########################################\n",
    "\n",
    "adj_model2 = model2.fit(training_images, training_labels, epochs = ep, validation_data=(test_images, test_labels))\n",
    "\n",
    "###########################################\n",
    "# Evaluacion del Modelo\n",
    "###########################################\n",
    "\n",
    "print(\"============================================================\")\n",
    "\n",
    "# Evaluamos el modelo según los valores test que nos proporcionan\n",
    "print(\"\\nEl accuracy de este modelo al evaluarlo es: {} \".format(model2.evaluate(test_images, test_labels)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "YXBlbbfuUaPa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.5025 - accuracy: 0.8189 - val_loss: 0.4384 - val_accuracy: 0.8422\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3852 - accuracy: 0.8590 - val_loss: 0.3984 - val_accuracy: 0.8547\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3421 - accuracy: 0.8731 - val_loss: 0.3775 - val_accuracy: 0.8663\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3108 - accuracy: 0.8844 - val_loss: 0.3493 - val_accuracy: 0.8735\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2887 - accuracy: 0.8921 - val_loss: 0.3446 - val_accuracy: 0.8734\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2690 - accuracy: 0.8989 - val_loss: 0.3348 - val_accuracy: 0.8824\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2527 - accuracy: 0.9051 - val_loss: 0.3276 - val_accuracy: 0.8848\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2386 - accuracy: 0.9094 - val_loss: 0.3224 - val_accuracy: 0.8854\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2250 - accuracy: 0.9146 - val_loss: 0.3307 - val_accuracy: 0.8854\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2141 - accuracy: 0.9190 - val_loss: 0.3161 - val_accuracy: 0.8919\n",
      "============================================================\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8919\n",
      "\n",
      "El accuracy de este modelo al evaluarlo es: 0.8919000029563904 \n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Creacion del Modelo\n",
    "###########################################\n",
    "\n",
    "# Creamos el modelo de Red Neuronal secuencial\n",
    "model3 = keras.models.Sequential()\n",
    "\n",
    "# Creamos la capa de entrada\n",
    "model3.add(keras.layers.Flatten(input_shape = sz_image))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model3.add(keras.layers.Dense(1024, activation = fun_hid_layer))\n",
    "\n",
    "# Creamos la capa de salida\n",
    "model3.add(keras.layers.Dense(tags, activation = fun_output_layer))\n",
    "\n",
    "# Modificamos los parámetros del modelo\n",
    "model3.compile(loss=\"sparse_categorical_crossentropy\", optimizer = opt, metrics = metr, steps_per_execution = sz_batch)\n",
    "\n",
    "###########################################\n",
    "# Ajuste del Modelo\n",
    "###########################################\n",
    "\n",
    "adj_model3 = model3.fit(training_images, training_labels, epochs = ep, validation_data=(test_images, test_labels))\n",
    "\n",
    "###########################################\n",
    "# Evaluacion del Modelo\n",
    "###########################################\n",
    "\n",
    "print(\"============================================================\")\n",
    "\n",
    "# Evaluamos el modelo según los valores test que nos proporcionan\n",
    "print(\"\\nEl accuracy de este modelo al evaluarlo es: {} \".format(model3.evaluate(test_images, test_labels)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wG0h2HL-Uj93"
   },
   "source": [
    "**pregunta 4.1 (0.5 puntos)**: ¿Cuál es el impacto que tiene la red neuronal? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkZYq4xBvnrS"
   },
   "source": [
    "Pues los principales cambios serían:\n",
    "* Aumento de tiempo por cada época.\n",
    "* Aumento del accuracy y descenso de la función de perdida que mejora nuestra predicción, pero que puede llevar a un sobreajuste no deseado-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-NpUI9EVkVz"
   },
   "source": [
    "Si ahora entrenais el modelo de esta forma (con 512 y 1024 neuronas en la capa oculta) y volveis a ejecutar el predictor guardado en la variable **classifications**, escribir el código del clasificador del ejercicio 1 de nuevo e imprimid el primer objeto guardado en la variable classifications.\n",
    "\n",
    "**pregunta 4.2 (0.25 puntos)**: \n",
    "\n",
    "* ¿En qué clase está clasificado ahora la primera prenda de vestir de la variable classifications?\n",
    "\n",
    "**pregunta 4.3 (0.25 puntos)**: \n",
    "\n",
    "* ¿Por qué crees que ha ocurrido esto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "RdJHl3V-G4iS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 914us/step\n",
      "313/313 [==============================] - 0s 1ms/step\n",
      "Clasificación del modelo de 128 neuronas: 9, del modelo de 512 neuronas: 9 y del modelo de 1024 neuronas: 9\n"
     ]
    }
   ],
   "source": [
    "classifications2 = model2.predict(test_images)\n",
    "classifications3 = model3.predict(test_images)\n",
    "\n",
    "print(\"Clasificación del modelo de 128 neuronas: {}, del modelo de 512 neuronas: {} y del modelo de 1024 neuronas: {}\".format(classifications[0].argmax(), classifications2[0].argmax(), classifications3[0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3NfwdOGZcAa"
   },
   "source": [
    "<b>Respuesta a la pregunta 4.2:</b>\n",
    "Suponiendo que la pregunta se refiere a la posicion 0 cuando se refiere al primer elemento, los tres modelos clasifican igual, es decir, la etiqueta 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFmfpxE1ZcJx"
   },
   "source": [
    "<b>Respuesta a la pregunta 4.3:</b>\n",
    "Porque se ha mejorado el accuracy en los modelos progresivamente añadiendo más neuronas conforme se ha añadido "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59eM76O1YekZ"
   },
   "source": [
    "## 5: Capa Flatten\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6LGnSxBu-ww"
   },
   "source": [
    "En este ejercicio vamos a ver que ocurre cuando quitamos la capa flatten, para ello, escribe la red neuronal de la pregunta 1 y no pongas la capa Flatten.\n",
    "\n",
    "**pregunta 5 (0.5 puntos):** ¿Puedes explicar a qué se debe el error que da?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ecfEVKEuG4iU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Error\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "        ###########################################\n",
    "        # Creacion del Modelo\n",
    "        ###########################################\n",
    "\n",
    "        # Creamos el modelo de Red Neuronal secuencial\n",
    "        model4 = keras.models.Sequential()\n",
    "\n",
    "        # Creamos una única capa oculta con 128 neuronas\n",
    "        model4.add(keras.layers.Dense(sz_hid_layer, activation = fun_hid_layer))\n",
    "\n",
    "        # Creamos la capa de salida\n",
    "        model4.add(keras.layers.Dense(tags, activation = fun_output_layer))\n",
    "\n",
    "        # Modificamos los parámetros del modelo\n",
    "        model4.compile(loss=\"sparse_categorical_crossentropy\", optimizer = opt, metrics = metr, steps_per_execution = sz_batch)\n",
    "\n",
    "\n",
    "\n",
    "        ###########################################\n",
    "        # Ajuste del Modelo\n",
    "        ###########################################\n",
    "\n",
    "        adj_model4 = model4.fit(training_images, training_labels, epochs = ep, validation_data=(test_images, test_labels))\n",
    "        \n",
    "        ###########################################\n",
    "        # Evaluacion del Modelo\n",
    "        ###########################################\n",
    "\n",
    "        print(\"============================================================\")\n",
    "\n",
    "        # Evaluamos el modelo según los valores test que nos proporcionan\n",
    "        print(\"\\nEl accuracy de este modelo al evaluarlo es: {} \".format(model4.evaluate(test_images, test_labels)[1]))\n",
    "        \n",
    "except:\n",
    "        print(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aNmrkkOZN6D"
   },
   "source": [
    "<b>Respuesta a la pregunta 5:</b>\n",
    "El modelo lanza un error ya que no coincide los tamaños de la entrada con lo que se quiere conseguir ya que la funcion flatten convierte la entrada a un vector de 1x(28x28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f37cIr81ZYJj"
   },
   "source": [
    "## 6: Número de neuronas de la capa de salida\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zk1xYVAQu0wN"
   },
   "source": [
    "Considerad la capa final, la de salida de la red neuronal de la pregunta 1.\n",
    "\n",
    "**pregunta 6.1 (0.25 puntos)**: ¿Por qué son 10 las neuronas de la última capa?\n",
    "\n",
    "**pregunta 6.2 (0.25 puntos)**: ¿Qué pasaría si tuvieras una cantidad diferente a 10? \n",
    "\n",
    "Por ejemplo, intenta entrenar la red con 5, para ello utiliza la red neuronal de la pregunta 1 y cambia a 5 el número de neuronas en la última capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "FhbZkppYZOCS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Error\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    \n",
    "    ###########################################\n",
    "    # Creacion del Modelo\n",
    "    ###########################################\n",
    "\n",
    "    # Creamos el modelo de Red Neuronal secuencial\n",
    "    model5 = keras.models.Sequential()\n",
    "\n",
    "    # Creamos la capa de entrada\n",
    "    model5.add(keras.layers.Flatten(input_shape = sz_image))\n",
    "\n",
    "    # Creamos una única capa oculta con 128 neuronas\n",
    "    model5.add(keras.layers.Dense(sz_hid_layer, activation = fun_hid_layer))\n",
    "\n",
    "    # Creamos la capa de salida\n",
    "    model5.add(keras.layers.Dense(5, activation = fun_output_layer))\n",
    "\n",
    "    # Modificamos los parámetros del modelo\n",
    "    model5.compile(loss=\"sparse_categorical_crossentropy\", optimizer = opt, metrics = metr, steps_per_execution = sz_batch)\n",
    "\n",
    "\n",
    "\n",
    "    ###########################################\n",
    "    # Ajuste del Modelo\n",
    "    ###########################################\n",
    "\n",
    "    adj_model5 = model5.fit(training_images, training_labels, epochs = ep, validation_data=(test_images, test_labels))\n",
    "    \n",
    "    ###########################################\n",
    "    # Evaluacion del Modelo\n",
    "    ###########################################\n",
    "\n",
    "    print(\"============================================================\")\n",
    "\n",
    "    # Evaluamos el modelo según los valores test que nos proporcionan\n",
    "    print(\"\\nEl accuracy de este modelo al evaluarlo es: {} \".format(model5.evaluate(test_images, test_labels)[1]))\n",
    "    \n",
    "except:\n",
    "    \n",
    "    print(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLsQcq-6aUoD"
   },
   "source": [
    "<b>Respuesta a la pregunta 6.1:</b>\n",
    "El modelo tiene 10 neuronas de salida ya que existen 10 etiquetas distintas, por lo que cada neurona evalúa si la imagen se puede clasificar como la etiqueta que representa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1f_7ZFeaUu6"
   },
   "source": [
    "<b>Respuesta a la pregunta 6.2:</b> Como se puede observar, si cambiamos las neuronas de la capa de salida por 5, no sabe como clasificar 10 etiquetas en 5 neuronas, por lo que lanza un error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNIBCkshaf2y"
   },
   "source": [
    "## 7: Aumento de epoch y su efecto en la red neuronal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yg8tTqYPuwGc"
   },
   "source": [
    "En este ejercicio vamos a ver el impacto de aumentar los epoch en el entrenamiento. Usando la red neuronal de la pregunta 1:\n",
    "\n",
    "**pregunta 7.1 (0.15 puntos)**\n",
    "* Intentad 15 epoch para su entrenamiento, probablemente obtendras un modelo con una pérdida mucho mejor que el que tiene 5.\n",
    "\n",
    "**pregunta 7.2 (0.15 puntos)**\n",
    "* Intenta ahora con 30 epoch para su entrenamiento, podrás ver que el valor de la pérdida deja de disminuir, y a veces aumenta.\n",
    "\n",
    "**pregunta 7.3 (0.20 puntos)**\n",
    "* ¿Por qué piensas que ocurre esto? Explica tu respuesta y da el nombre de este efecto si lo conoces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Cb5vk_imG4iZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5427 - accuracy: 0.8148 - val_loss: 0.4560 - val_accuracy: 0.8377\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 1s 652us/step - loss: 0.3912 - accuracy: 0.8592 - val_loss: 0.4106 - val_accuracy: 0.8526\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 1s 579us/step - loss: 0.3534 - accuracy: 0.8728 - val_loss: 0.3805 - val_accuracy: 0.8659\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 1s 651us/step - loss: 0.3294 - accuracy: 0.8809 - val_loss: 0.3706 - val_accuracy: 0.8677\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 1s 605us/step - loss: 0.3103 - accuracy: 0.8875 - val_loss: 0.3657 - val_accuracy: 0.8683\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 1s 576us/step - loss: 0.2957 - accuracy: 0.8921 - val_loss: 0.3527 - val_accuracy: 0.8730\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 1s 584us/step - loss: 0.2822 - accuracy: 0.8970 - val_loss: 0.3461 - val_accuracy: 0.8754\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 1s 576us/step - loss: 0.2725 - accuracy: 0.8997 - val_loss: 0.3272 - val_accuracy: 0.8803\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 1s 666us/step - loss: 0.2608 - accuracy: 0.9044 - val_loss: 0.3218 - val_accuracy: 0.8843\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 1s 657us/step - loss: 0.2514 - accuracy: 0.9070 - val_loss: 0.3280 - val_accuracy: 0.8795\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 1s 734us/step - loss: 0.2433 - accuracy: 0.9104 - val_loss: 0.3448 - val_accuracy: 0.8757\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 1s 575us/step - loss: 0.2352 - accuracy: 0.9132 - val_loss: 0.3224 - val_accuracy: 0.8853\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 1s 605us/step - loss: 0.2282 - accuracy: 0.9151 - val_loss: 0.3203 - val_accuracy: 0.8878\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 1s 577us/step - loss: 0.2213 - accuracy: 0.9179 - val_loss: 0.3170 - val_accuracy: 0.8862\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 1s 589us/step - loss: 0.2128 - accuracy: 0.9214 - val_loss: 0.3230 - val_accuracy: 0.8872\n",
      "============================================================\n",
      "313/313 [==============================] - 0s 288us/step - loss: 0.3230 - accuracy: 0.8872\n",
      "\n",
      "El accuracy de este modelo al evaluarlo es: 0.8871999979019165 \n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Creacion del Modelo\n",
    "###########################################\n",
    "\n",
    "# Creamos el modelo de Red Neuronal secuencial\n",
    "model6 = keras.models.Sequential()\n",
    "\n",
    "# Creamos la capa de entrada\n",
    "model6.add(keras.layers.Flatten(input_shape = sz_image))\n",
    "\n",
    "# Creamos una única capa oculta con 128 neuronas\n",
    "model6.add(keras.layers.Dense(sz_hid_layer, activation = fun_hid_layer))\n",
    "\n",
    "# Creamos la capa de salida\n",
    "model6.add(keras.layers.Dense(tags, activation = fun_output_layer))\n",
    "\n",
    "# Modificamos los parámetros del modelo\n",
    "model6.compile(loss=\"sparse_categorical_crossentropy\", optimizer = opt, metrics = metr, steps_per_execution = sz_batch)\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "# Ajuste del Modelo\n",
    "###########################################\n",
    "\n",
    "adj_model6 = model6.fit(training_images, training_labels, epochs = 15, validation_data=(test_images, test_labels))\n",
    "\n",
    "###########################################\n",
    "# Evaluacion del Modelo\n",
    "###########################################\n",
    "\n",
    "print(\"============================================================\")\n",
    "\n",
    "# Evaluamos el modelo según los valores test que nos proporcionan\n",
    "print(\"\\nEl accuracy de este modelo al evaluarlo es: {} \".format(model6.evaluate(test_images, test_labels)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "I9jQ26Gda5cv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5414 - accuracy: 0.8131 - val_loss: 0.4588 - val_accuracy: 0.8321\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 1s 601us/step - loss: 0.3934 - accuracy: 0.8575 - val_loss: 0.4034 - val_accuracy: 0.8536\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 1s 574us/step - loss: 0.3553 - accuracy: 0.8718 - val_loss: 0.3859 - val_accuracy: 0.8607\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 1s 585us/step - loss: 0.3305 - accuracy: 0.8791 - val_loss: 0.3720 - val_accuracy: 0.8639\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 1s 587us/step - loss: 0.3115 - accuracy: 0.8876 - val_loss: 0.3608 - val_accuracy: 0.8721\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 1s 613us/step - loss: 0.2975 - accuracy: 0.8915 - val_loss: 0.3612 - val_accuracy: 0.8680\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 1s 616us/step - loss: 0.2839 - accuracy: 0.8954 - val_loss: 0.3445 - val_accuracy: 0.8758\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 1s 641us/step - loss: 0.2725 - accuracy: 0.9001 - val_loss: 0.3421 - val_accuracy: 0.8764\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 1s 597us/step - loss: 0.2628 - accuracy: 0.9022 - val_loss: 0.3330 - val_accuracy: 0.8796\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 1s 593us/step - loss: 0.2542 - accuracy: 0.9053 - val_loss: 0.3341 - val_accuracy: 0.8784\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 1s 636us/step - loss: 0.2449 - accuracy: 0.9096 - val_loss: 0.3293 - val_accuracy: 0.8792\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 1s 670us/step - loss: 0.2366 - accuracy: 0.9134 - val_loss: 0.3318 - val_accuracy: 0.8783\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 1s 635us/step - loss: 0.2290 - accuracy: 0.9170 - val_loss: 0.3258 - val_accuracy: 0.8825\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 1s 572us/step - loss: 0.2226 - accuracy: 0.9185 - val_loss: 0.3253 - val_accuracy: 0.8816\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 1s 598us/step - loss: 0.2147 - accuracy: 0.9208 - val_loss: 0.3252 - val_accuracy: 0.8819\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 1s 598us/step - loss: 0.2102 - accuracy: 0.9223 - val_loss: 0.3198 - val_accuracy: 0.8864\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 1s 611us/step - loss: 0.2035 - accuracy: 0.9258 - val_loss: 0.3238 - val_accuracy: 0.8852\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 1s 593us/step - loss: 0.1971 - accuracy: 0.9276 - val_loss: 0.3238 - val_accuracy: 0.8841\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 1s 614us/step - loss: 0.1933 - accuracy: 0.9294 - val_loss: 0.3233 - val_accuracy: 0.8856\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 1s 623us/step - loss: 0.1885 - accuracy: 0.9307 - val_loss: 0.3259 - val_accuracy: 0.8846\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 1s 622us/step - loss: 0.1823 - accuracy: 0.9329 - val_loss: 0.3218 - val_accuracy: 0.8896\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 1s 610us/step - loss: 0.1771 - accuracy: 0.9352 - val_loss: 0.3223 - val_accuracy: 0.8867\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 1s 609us/step - loss: 0.1728 - accuracy: 0.9367 - val_loss: 0.3243 - val_accuracy: 0.8875\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 1s 620us/step - loss: 0.1690 - accuracy: 0.9380 - val_loss: 0.3274 - val_accuracy: 0.8871\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 1s 609us/step - loss: 0.1644 - accuracy: 0.9400 - val_loss: 0.3328 - val_accuracy: 0.8892\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 1s 612us/step - loss: 0.1599 - accuracy: 0.9425 - val_loss: 0.3291 - val_accuracy: 0.8894\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 1s 610us/step - loss: 0.1569 - accuracy: 0.9427 - val_loss: 0.3276 - val_accuracy: 0.8889\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 1s 623us/step - loss: 0.1513 - accuracy: 0.9452 - val_loss: 0.3252 - val_accuracy: 0.8902\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 1s 609us/step - loss: 0.1474 - accuracy: 0.9468 - val_loss: 0.3284 - val_accuracy: 0.8890\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 1s 621us/step - loss: 0.1455 - accuracy: 0.9464 - val_loss: 0.3387 - val_accuracy: 0.8861\n",
      "============================================================\n",
      "313/313 [==============================] - 0s 304us/step - loss: 0.3387 - accuracy: 0.8861\n",
      "\n",
      "El accuracy de este modelo al evaluarlo es: 0.8860999941825867 \n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Creacion del Modelo\n",
    "###########################################\n",
    "\n",
    "# Creamos el modelo de Red Neuronal secuencial\n",
    "model7 = keras.models.Sequential()\n",
    "\n",
    "# Creamos la capa de entrada\n",
    "model7.add(keras.layers.Flatten(input_shape = sz_image))\n",
    "\n",
    "# Creamos una única capa oculta con 128 neuronas\n",
    "model7.add(keras.layers.Dense(sz_hid_layer, activation = fun_hid_layer))\n",
    "\n",
    "# Creamos la capa de salida\n",
    "model7.add(keras.layers.Dense(tags, activation = fun_output_layer))\n",
    "\n",
    "# Modificamos los parámetros del modelo\n",
    "model7.compile(loss=\"sparse_categorical_crossentropy\", optimizer = opt, metrics = metr, steps_per_execution = sz_batch)\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "# Ajuste del Modelo\n",
    "###########################################\n",
    "\n",
    "adj_model7 = model7.fit(training_images, training_labels, epochs = 30, validation_data=(test_images, test_labels))\n",
    "\n",
    "###########################################\n",
    "# Evaluacion del Modelo\n",
    "###########################################\n",
    "\n",
    "print(\"============================================================\")\n",
    "\n",
    "# Evaluamos el modelo según los valores test que nos proporcionan\n",
    "print(\"\\nEl accuracy de este modelo al evaluarlo es: {} \".format(model7.evaluate(test_images, test_labels)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fs0fjzH4bmSR"
   },
   "source": [
    "<b>Respuesta a la pregunta 7.3:</b>\n",
    "Una red neuronal con más épocas (iteraciones) es capaz de realizar más veces el proceso de back propagation y es capaz de corregir el error mejor que una que tiene menos épocas. Aunque en este caso, el aumentar las épocas estamos variando el loss y el accuracy llegando a un sobreentrenar la red dando peores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlIgNG4Yb_N6"
   },
   "source": [
    "## 8: Early stop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06rrpDXqupAA"
   },
   "source": [
    "En el ejercicio anterior, cuando entrenabas con epoch extras, tenías un problema en el que tu pérdida podía cambiar. Puede que te haya llevado un poco de tiempo esperar a que el entrenamiento lo hiciera,  y puede que hayas pensado \"¿no estaría bien si pudiera parar el entrenamiento cuando alcance un valor deseado?\", es decir, una precisión del 85% podría ser suficiente para ti, y si alcanzas eso después de 3 epoch, ¿por qué sentarte a esperar a que termine muchas más épocas? Como cualquier otro programa existen formas de parar la ejecución\n",
    "\n",
    "A partir del código de ejemplo, hacer una nueva función que tenga en cuenta la perdida (loss) y que pueda parar el código para evitar que ocurra el efeto secundario que vimos en el ejercicio 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "b5UwceFUG4ic"
   },
   "outputs": [],
   "source": [
    "##### Ejemplo de código\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')> 0.85):\n",
    "              print(\"\\nAlcanzado el 85% de precisión, se cancela el entrenamiento!!\")\n",
    "              self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Bjd8wGKccrn"
   },
   "source": [
    "**Ejercicio 8 *(0.75 puntos)***: Completa el siguiente código con una clase callback que una vez alcanzado el 40% de perdida detenga el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "29LSfdOvc270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4707 - accuracy: 0.8319\n",
      "Epoch 2/50\n",
      "1871/1875 [============================>.] - ETA: 0s - loss: 0.3594 - accuracy: 0.8689\n",
      "Alcanzado el 40% de loss, se cancela el entrenamiento!!\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3594 - accuracy: 0.8689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2616252bc50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "### Tu código de la función callback para parar el entrenamiento de la red neuronal al 40% de loss aqui: ###\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('loss') <= 0.40):\n",
    "              print(\"\\nAlcanzado el 40% de loss, se cancela el entrenamiento!!\")\n",
    "              self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model8 = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model8.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "model8.fit(training_images, training_labels, epochs=50, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_yZ9B8gTFqR"
   },
   "source": [
    "## 9. Unidades de activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuVNxmXSTFqR"
   },
   "source": [
    "En este ejercicio, vamos a evaluar la importancia de utilizar las unidades de activación adecuadas. Como hemos visto en clase, funciones de activación como sigmoid han dejado de utilizarse en favor de otras unidades como ReLU.\n",
    "\n",
    "**Ejercicio 9 *(0.75 puntos)***: Partiendo de una red sencilla como la desarrollada en el Trabajo 1, escribir un breve análisis comparando la utilización de unidades sigmoid y ReLU (por ejemplo, se pueden comentar aspectos como velocidad de convergencia, métricas obtenidas...). Explicar por qué pueden darse estas diferencias. Opcionalmente, comparar con otras activaciones disponibles en Keras.\n",
    "\n",
    "*Pista: Usando redes más grandes se hace más sencillo apreciar las diferencias. Es mejor utilizar al menos 3 o 4 capas densas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "hoYUajTuTFqS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 42s 23ms/step - loss: 0.5658 - accuracy: 0.7942 - val_loss: 0.4240 - val_accuracy: 0.8468\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.3816 - accuracy: 0.8614 - val_loss: 0.3959 - val_accuracy: 0.8547\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.3374 - accuracy: 0.8754 - val_loss: 0.3591 - val_accuracy: 0.8689\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.3090 - accuracy: 0.8856 - val_loss: 0.3703 - val_accuracy: 0.8672\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.2877 - accuracy: 0.8933 - val_loss: 0.3535 - val_accuracy: 0.8711\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.2702 - accuracy: 0.8992 - val_loss: 0.3299 - val_accuracy: 0.8829\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2540 - accuracy: 0.9044 - val_loss: 0.3433 - val_accuracy: 0.8787\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.2398 - accuracy: 0.9093 - val_loss: 0.3252 - val_accuracy: 0.8853\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 40s 22ms/step - loss: 0.2297 - accuracy: 0.9131 - val_loss: 0.3324 - val_accuracy: 0.8819\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2188 - accuracy: 0.9168 - val_loss: 0.3501 - val_accuracy: 0.8797\n",
      "============================================================\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3501 - accuracy: 0.8797\n",
      "\n",
      "El accuracy de este modelo al evaluarlo es: 0.8797000050544739 \n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Creacion del Modelo\n",
    "###########################################\n",
    "\n",
    "# Creamos el modelo de Red Neuronal secuencial\n",
    "model9 = keras.models.Sequential()\n",
    "\n",
    "# Creamos la capa de entrada\n",
    "model9.add(keras.layers.Flatten(input_shape = sz_image))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model9.add(keras.layers.Dense(1024, activation = fun_hid_layer))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model9.add(keras.layers.Dense(1024, activation = fun_hid_layer))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model9.add(keras.layers.Dense(1024, activation = fun_hid_layer))\n",
    "\n",
    "# Creamos la capa de salida\n",
    "model9.add(keras.layers.Dense(tags, activation = fun_output_layer))\n",
    "\n",
    "# Modificamos los parámetros del modelo\n",
    "model9.compile(loss=\"sparse_categorical_crossentropy\", optimizer = opt, metrics = metr, steps_per_execution = sz_batch)\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "# Ajuste del Modelo\n",
    "###########################################\n",
    "\n",
    "adj_model9 = model9.fit(training_images, training_labels, epochs = ep, validation_data=(test_images, test_labels))\n",
    "\n",
    "###########################################\n",
    "# Evaluacion del Modelo\n",
    "###########################################\n",
    "\n",
    "print(\"============================================================\")\n",
    "\n",
    "# Evaluamos el modelo según los valores test que nos proporcionan\n",
    "print(\"\\nEl accuracy de este modelo al evaluarlo es: {} \".format(model9.evaluate(test_images, test_labels)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.4889 - accuracy: 0.8231 - val_loss: 0.4389 - val_accuracy: 0.8440\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.3701 - accuracy: 0.8646 - val_loss: 0.4115 - val_accuracy: 0.8477\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.3328 - accuracy: 0.8788 - val_loss: 0.3716 - val_accuracy: 0.8631\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 38s 21ms/step - loss: 0.3077 - accuracy: 0.8863 - val_loss: 0.3621 - val_accuracy: 0.8754\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.2894 - accuracy: 0.8925 - val_loss: 0.3668 - val_accuracy: 0.8759\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2745 - accuracy: 0.8973 - val_loss: 0.3343 - val_accuracy: 0.8834\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2607 - accuracy: 0.9024 - val_loss: 0.3550 - val_accuracy: 0.8756\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.2535 - accuracy: 0.9038 - val_loss: 0.3557 - val_accuracy: 0.8805\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.2435 - accuracy: 0.9073 - val_loss: 0.3962 - val_accuracy: 0.8758\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2334 - accuracy: 0.9107 - val_loss: 0.3808 - val_accuracy: 0.8768\n",
      "============================================================\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3808 - accuracy: 0.8768\n",
      "\n",
      "El accuracy de este modelo al evaluarlo es: 0.876800000667572 \n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Creacion del Modelo\n",
    "###########################################\n",
    "\n",
    "# Creamos el modelo de Red Neuronal secuencial\n",
    "model10 = keras.models.Sequential()\n",
    "\n",
    "# Creamos la capa de entrada\n",
    "model10.add(keras.layers.Flatten(input_shape = sz_image))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model10.add(keras.layers.Dense(1024, activation = \"relu\"))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model10.add(keras.layers.Dense(1024, activation = \"relu\"))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model10.add(keras.layers.Dense(1024, activation = \"relu\"))\n",
    "\n",
    "# Creamos la capa de salida\n",
    "model10.add(keras.layers.Dense(tags, activation = fun_output_layer))\n",
    "\n",
    "# Modificamos los parámetros del modelo\n",
    "model10.compile(loss=\"sparse_categorical_crossentropy\", optimizer = opt, metrics = metr, steps_per_execution = sz_batch)\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "# Ajuste del Modelo\n",
    "###########################################\n",
    "\n",
    "adj_model10 = model10.fit(training_images, training_labels, epochs = ep, validation_data=(test_images, test_labels))\n",
    "\n",
    "###########################################\n",
    "# Evaluacion del Modelo\n",
    "###########################################\n",
    "\n",
    "print(\"============================================================\")\n",
    "\n",
    "# Evaluamos el modelo según los valores test que nos proporcionan\n",
    "print(\"\\nEl accuracy de este modelo al evaluarlo es: {} \".format(model10.evaluate(test_images, test_labels)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta a la pregunta 9:</b>\n",
    "\n",
    "- La función sigmoid es: $$ f(x) = { e^x \\over e^x + 1} $$\n",
    "\n",
    "- La función reLU es: $$ g(x) = max(0,x) $$\n",
    "\n",
    "Concretamente, hay dos principales diferencias:\n",
    "\n",
    "* La función reLU es objetivamente más sencilla de computar, mientras que la sigmoide es menos sencilla por el número de operaciones que realizan. Esto se ve en los segundos de computación de cada época. \n",
    "\n",
    "* El accuracy con la función reLU es menor que con la función sigmoide. Esto puede haberse dado porque la función sigmoide escala (encuentra patrones) de forma más suave/lenta que la la reLU. Se refleja en las tasas de pérdida donde una decrementa exponencialmente, mientras que la otra decrementa de forma lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pu6RbUFKTFqT"
   },
   "source": [
    "## 10. Inicialización de parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Abmm05UPTFqU"
   },
   "source": [
    "En este ejercicio, vamos a evaluar la importancia de una correcta inicialización de parámetros en una red neuronal.\n",
    "\n",
    "**Ejercicio 10 *(0.75 puntos)***: Partiendo de una red similar a la del ejercicio anterior (usando ya ReLUs), comentar las diferencias que se aprecian en el entrenamiento al utilizar distintas estrategias de inicialización de parámetros. Para ello, inicializar todas las capas con las siguientes estrategias, disponibles en Keras, y analizar sus diferencias:\n",
    "\n",
    "* Inicialización con ceros.\n",
    "* Inicialización con una variable aleatoria normal.\n",
    "* Inicialización con los valores por defecto de Keras para una capa Dense (estrategia *glorot uniform*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "qcMt7pSkTFqU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3028 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 2.3028 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 2.3028 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 2.3028 - accuracy: 0.0972 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 2.3028 - accuracy: 0.0972 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 2.3028 - accuracy: 0.0981 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 2.3028 - accuracy: 0.0976 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3028 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "============================================================\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.1000\n",
      "\n",
      "El accuracy de este modelo al evaluarlo es: 0.10000000149011612 \n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Creacion del Modelo\n",
    "###########################################\n",
    "\n",
    "# Creamos el modelo de Red Neuronal secuencial\n",
    "model11 = keras.models.Sequential()\n",
    "\n",
    "# Creamos la capa de entrada\n",
    "model11.add(keras.layers.Flatten(input_shape = sz_image))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model11.add(keras.layers.Dense(1024, activation = \"relu\", kernel_initializer=initializers.Zeros()))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model11.add(keras.layers.Dense(1024, activation = \"relu\", kernel_initializer=initializers.Zeros()))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model11.add(keras.layers.Dense(1024, activation = \"relu\", kernel_initializer=initializers.Zeros()))\n",
    "\n",
    "# Creamos la capa de salida\n",
    "model11.add(keras.layers.Dense(tags, activation = fun_output_layer, kernel_initializer=initializers.Zeros()))\n",
    "\n",
    "# Modificamos los parámetros del modelo\n",
    "model11.compile(loss=\"sparse_categorical_crossentropy\", optimizer = opt, metrics = metr, steps_per_execution = sz_batch)\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "# Ajuste del Modelo\n",
    "###########################################\n",
    "\n",
    "adj_model11 = model11.fit(training_images, training_labels, epochs = ep, validation_data=(test_images, test_labels))\n",
    "\n",
    "###########################################\n",
    "# Evaluacion del Modelo\n",
    "###########################################\n",
    "\n",
    "print(\"============================================================\")\n",
    "\n",
    "# Evaluamos el modelo según los valores test que nos proporcionan\n",
    "print(\"\\nEl accuracy de este modelo al evaluarlo es: {} \".format(model11.evaluate(test_images, test_labels)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.4803 - accuracy: 0.8254 - val_loss: 0.4283 - val_accuracy: 0.8475\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.3677 - accuracy: 0.8652 - val_loss: 0.3809 - val_accuracy: 0.8607\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 40s 22ms/step - loss: 0.3319 - accuracy: 0.8780 - val_loss: 0.3949 - val_accuracy: 0.8549\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.3072 - accuracy: 0.8861 - val_loss: 0.3682 - val_accuracy: 0.8685\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.2887 - accuracy: 0.8930 - val_loss: 0.3660 - val_accuracy: 0.8709\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2774 - accuracy: 0.8976 - val_loss: 0.3555 - val_accuracy: 0.8749\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2635 - accuracy: 0.9013 - val_loss: 0.3394 - val_accuracy: 0.8859\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2506 - accuracy: 0.9061 - val_loss: 0.3589 - val_accuracy: 0.8807\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.2449 - accuracy: 0.9081 - val_loss: 0.3629 - val_accuracy: 0.8824\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2329 - accuracy: 0.9125 - val_loss: 0.3470 - val_accuracy: 0.8821\n",
      "============================================================\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.8821\n",
      "\n",
      "El accuracy de este modelo al evaluarlo es: 0.882099986076355 \n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Creacion del Modelo\n",
    "###########################################\n",
    "\n",
    "# Creamos el modelo de Red Neuronal secuencial\n",
    "model12 = keras.models.Sequential()\n",
    "\n",
    "# Creamos la capa de entrada\n",
    "model12.add(keras.layers.Flatten(input_shape = sz_image))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model12.add(keras.layers.Dense(1024, activation = \"relu\", kernel_initializer=initializers.RandomNormal()))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model12.add(keras.layers.Dense(1024, activation = \"relu\", kernel_initializer=initializers.RandomNormal()))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model12.add(keras.layers.Dense(1024, activation = \"relu\", kernel_initializer=initializers.RandomNormal()))\n",
    "\n",
    "# Creamos la capa de salida\n",
    "model12.add(keras.layers.Dense(tags, activation = fun_output_layer, kernel_initializer=initializers.RandomNormal()))\n",
    "\n",
    "# Modificamos los parámetros del modelo\n",
    "model12.compile(loss=\"sparse_categorical_crossentropy\", optimizer = opt, metrics = metr, steps_per_execution = sz_batch)\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "# Ajuste del Modelo\n",
    "###########################################\n",
    "\n",
    "adj_model12 = model12.fit(training_images, training_labels, epochs = ep, validation_data=(test_images, test_labels))\n",
    "\n",
    "###########################################\n",
    "# Evaluacion del Modelo\n",
    "###########################################\n",
    "\n",
    "print(\"============================================================\")\n",
    "\n",
    "# Evaluamos el modelo según los valores test que nos proporcionan\n",
    "print(\"\\nEl accuracy de este modelo al evaluarlo es: {} \".format(model12.evaluate(test_images, test_labels)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.4879 - accuracy: 0.8230 - val_loss: 0.4474 - val_accuracy: 0.8422\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.3686 - accuracy: 0.8652 - val_loss: 0.3934 - val_accuracy: 0.8607\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.3345 - accuracy: 0.8762 - val_loss: 0.3732 - val_accuracy: 0.8646\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.3078 - accuracy: 0.8863 - val_loss: 0.3527 - val_accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2926 - accuracy: 0.8921 - val_loss: 0.3759 - val_accuracy: 0.8749\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 38s 21ms/step - loss: 0.2754 - accuracy: 0.8973 - val_loss: 0.3378 - val_accuracy: 0.8795\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.2677 - accuracy: 0.9003 - val_loss: 0.3395 - val_accuracy: 0.8774\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.2534 - accuracy: 0.9042 - val_loss: 0.3440 - val_accuracy: 0.8808\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2434 - accuracy: 0.9085 - val_loss: 0.3292 - val_accuracy: 0.8870\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2348 - accuracy: 0.9123 - val_loss: 0.3457 - val_accuracy: 0.8879\n",
      "============================================================\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3457 - accuracy: 0.8879\n",
      "\n",
      "El accuracy de este modelo al evaluarlo es: 0.8878999948501587 \n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Creacion del Modelo\n",
    "###########################################\n",
    "\n",
    "# Creamos el modelo de Red Neuronal secuencial\n",
    "model13 = keras.models.Sequential()\n",
    "\n",
    "# Creamos la capa de entrada\n",
    "model13.add(keras.layers.Flatten(input_shape = sz_image))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model13.add(keras.layers.Dense(1024, activation = \"relu\", kernel_initializer=initializers.GlorotUniform()))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model13.add(keras.layers.Dense(1024, activation = \"relu\", kernel_initializer=initializers.GlorotUniform()))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model13.add(keras.layers.Dense(1024, activation = \"relu\", kernel_initializer=initializers.GlorotUniform()))\n",
    "\n",
    "# Creamos la capa de salida\n",
    "model13.add(keras.layers.Dense(tags, activation = fun_output_layer, kernel_initializer=initializers.GlorotUniform()))\n",
    "\n",
    "# Modificamos los parámetros del modelo\n",
    "model13.compile(loss=\"sparse_categorical_crossentropy\", optimizer = opt, metrics = metr, steps_per_execution = sz_batch)\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "# Ajuste del Modelo\n",
    "###########################################\n",
    "\n",
    "adj_model13 = model13.fit(training_images, training_labels, epochs = ep, validation_data=(test_images, test_labels))\n",
    "\n",
    "###########################################\n",
    "# Evaluacion del Modelo\n",
    "###########################################\n",
    "\n",
    "print(\"============================================================\")\n",
    "\n",
    "# Evaluamos el modelo según los valores test que nos proporcionan\n",
    "print(\"\\nEl accuracy de este modelo al evaluarlo es: {} \".format(model13.evaluate(test_images, test_labels)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta a la pregunta 10:</b>\n",
    "* La inicialización con ceros es pésima ya que la tasa de pérdida es muy grande y se mantiene constante, y el accuracy decrementa conforme va avanzando las épocas. Esto significa que no encuentra patrones porque la inicialización es muy mala.\n",
    "* La inicialización con distribución normal y con distribución Glorot Uniforme son bastante mejor ya que el accuracy final es cercano al 90% en ambos casos. La diferencia es que una inicializa los pesos de manera uniforme, mientras que la otra trabaja con una distribución normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqIAyVWrTFqV"
   },
   "source": [
    "## 11. Optimizadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcYj29hYTFqW"
   },
   "source": [
    "**Ejercicio 11 *(0.75 puntos)***: Partiendo de una red similar a la del ejercicio anterior (utilizando la mejor estrategia de inicialización observada), comparar y analizar las diferencias que se observan  al entrenar con varios de los optimizadores vistos en clase, incluyendo SGD como optimizador básico (se puede explorar el espacio de hiperparámetros de cada optimizador, aunque para optimizadores más avanzados del estilo de adam y RMSprop es buena idea dejar los valores por defecto provistos por Keras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "0fWDiqXvTFqW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.6672 - accuracy: 0.7764 - val_loss: 0.5073 - val_accuracy: 0.8205\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.4525 - accuracy: 0.8401 - val_loss: 0.4443 - val_accuracy: 0.8400\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.4069 - accuracy: 0.8561 - val_loss: 0.4277 - val_accuracy: 0.8456\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.3771 - accuracy: 0.8651 - val_loss: 0.4272 - val_accuracy: 0.8407\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3549 - accuracy: 0.8739 - val_loss: 0.3794 - val_accuracy: 0.8662\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3370 - accuracy: 0.8788 - val_loss: 0.3789 - val_accuracy: 0.8627\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3217 - accuracy: 0.8852 - val_loss: 0.3744 - val_accuracy: 0.8645\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3089 - accuracy: 0.8886 - val_loss: 0.3605 - val_accuracy: 0.8702\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2976 - accuracy: 0.8925 - val_loss: 0.3614 - val_accuracy: 0.8663\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2869 - accuracy: 0.8959 - val_loss: 0.3503 - val_accuracy: 0.8713\n",
      "============================================================\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3503 - accuracy: 0.8713\n",
      "\n",
      "El accuracy de este modelo al evaluarlo es: 0.8712999820709229 \n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Creacion del Modelo\n",
    "###########################################\n",
    "\n",
    "# Creamos el modelo de Red Neuronal secuencial\n",
    "model14 = keras.models.Sequential()\n",
    "\n",
    "# Creamos la capa de entrada\n",
    "model14.add(keras.layers.Flatten(input_shape = sz_image))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model14.add(keras.layers.Dense(1024, activation = \"relu\", kernel_initializer=initializers.GlorotUniform()))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model14.add(keras.layers.Dense(1024, activation = \"relu\", kernel_initializer=initializers.GlorotUniform()))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model14.add(keras.layers.Dense(1024, activation = \"relu\", kernel_initializer=initializers.GlorotUniform()))\n",
    "\n",
    "# Creamos la capa de salida\n",
    "model14.add(keras.layers.Dense(tags, activation = fun_output_layer, kernel_initializer=initializers.GlorotUniform()))\n",
    "\n",
    "# Modificamos los parámetros del modelo\n",
    "model14.compile(loss=\"sparse_categorical_crossentropy\", optimizer = \"SGD\", metrics = metr, steps_per_execution = sz_batch)\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "# Ajuste del Modelo\n",
    "###########################################\n",
    "\n",
    "adj_model14 = model14.fit(training_images, training_labels, epochs = ep, validation_data=(test_images, test_labels))\n",
    "\n",
    "###########################################\n",
    "# Evaluacion del Modelo\n",
    "###########################################\n",
    "\n",
    "print(\"============================================================\")\n",
    "\n",
    "# Evaluamos el modelo según los valores test que nos proporcionan\n",
    "print(\"\\nEl accuracy de este modelo al evaluarlo es: {} \".format(model14.evaluate(test_images, test_labels)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 0.5360 - accuracy: 0.8059 - val_loss: 0.4957 - val_accuracy: 0.8493\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.4190 - accuracy: 0.8538 - val_loss: 0.4352 - val_accuracy: 0.8527\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.4013 - accuracy: 0.8632 - val_loss: 0.3971 - val_accuracy: 0.8689\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.3925 - accuracy: 0.8660 - val_loss: 0.4262 - val_accuracy: 0.8625\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.3825 - accuracy: 0.8698 - val_loss: 0.5085 - val_accuracy: 0.8501\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.3801 - accuracy: 0.8730 - val_loss: 0.5945 - val_accuracy: 0.8449\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.3857 - accuracy: 0.8709 - val_loss: 0.4404 - val_accuracy: 0.8559\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.3884 - accuracy: 0.8738 - val_loss: 0.5461 - val_accuracy: 0.8261\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 0.3885 - accuracy: 0.8741 - val_loss: 0.6155 - val_accuracy: 0.8635\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.3899 - accuracy: 0.8733 - val_loss: 0.4555 - val_accuracy: 0.8627\n",
      "============================================================\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4555 - accuracy: 0.8627\n",
      "\n",
      "El accuracy de este modelo al evaluarlo es: 0.8626999855041504 \n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Creacion del Modelo\n",
    "###########################################\n",
    "\n",
    "# Creamos el modelo de Red Neuronal secuencial\n",
    "model15 = keras.models.Sequential()\n",
    "\n",
    "# Creamos la capa de entrada\n",
    "model15.add(keras.layers.Flatten(input_shape = sz_image))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model15.add(keras.layers.Dense(1024, activation = \"relu\", kernel_initializer=initializers.GlorotUniform()))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model15.add(keras.layers.Dense(1024, activation = \"relu\", kernel_initializer=initializers.GlorotUniform()))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model15.add(keras.layers.Dense(1024, activation = \"relu\", kernel_initializer=initializers.GlorotUniform()))\n",
    "\n",
    "# Creamos la capa de salida\n",
    "model15.add(keras.layers.Dense(tags, activation = fun_output_layer, kernel_initializer=initializers.GlorotUniform()))\n",
    "\n",
    "# Modificamos los parámetros del modelo\n",
    "model15.compile(loss=\"sparse_categorical_crossentropy\", optimizer = \"RMSprop\", metrics = metr, steps_per_execution = sz_batch)\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "# Ajuste del Modelo\n",
    "###########################################\n",
    "\n",
    "adj_model15 = model15.fit(training_images, training_labels, epochs = ep, validation_data=(test_images, test_labels))\n",
    "\n",
    "###########################################\n",
    "# Evaluacion del Modelo\n",
    "###########################################\n",
    "\n",
    "print(\"============================================================\")\n",
    "\n",
    "# Evaluamos el modelo según los valores test que nos proporcionan\n",
    "print(\"\\nEl accuracy de este modelo al evaluarlo es: {} \".format(model15.evaluate(test_images, test_labels)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta a la pregunta 11:</b>\n",
    "- El optimizador Adam es el que mejor funciona de los tres, pero el que mayor tiempo tarda en cada época. Dicho optimizador se basa en la optimización del método de descenso del gradiente de forma estocástica mediante los momentos de primer y segundo orden.\n",
    "- El optimizador SGD se basa en el método de descenso del gradiente común, por ese mismo motivo es el optimizador que menor tiempo tiempo por cada época.\n",
    "- El optimizador RMSprop utiliza una optimización del método de descenso del gradiente basado en el algoritmo de RMSprop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkfTFoJOTFqZ"
   },
   "source": [
    "## 12. Regularización y red final "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6CQhK7ZTFqZ"
   },
   "source": [
    "**Ejercicio 12 *(1 punto)***: Entrenar una red final que sea capaz de obtener una accuracy en el validation set cercana al 90%. Para ello, combinar todo lo aprendido anteriormente y utilizar técnicas de regularización para evitar overfitting. Algunos de los elementos que pueden tenerse en cuenta son los siguientes.\n",
    "\n",
    "* Número de capas y neuronas por capa\n",
    "* Optimizadores y sus parámetros\n",
    "* Batch size\n",
    "* Unidades de activación\n",
    "* Uso de capas dropout, regularización L2, regularización L1...\n",
    "* Early stopping (se puede aplicar como un callback de Keras, o se puede ver un poco \"a ojo\" cuándo el modelo empieza a caer en overfitting y seleccionar el número de epochs necesarias)\n",
    "* Batch normalization\n",
    "\n",
    "Si los modelos entrenados anteriormente ya se acercaban al valor requerido de accuracy, probar distintas estrategias igualmente y comentar los resultados.\n",
    "\n",
    "Explicar brevemente la estrategia seguida y los modelos probados para obtener el modelo final, que debe verse entrenado en este Notebook. No es necesario guardar el entrenamiento de todos los modelos que se han probado, es suficiente con explicar cómo se ha llegado al modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 259us/step - loss: 0.3290 - accuracy: 0.8810\n",
      "313/313 [==============================] - 0s 642us/step - loss: 0.3271 - accuracy: 0.8850\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8919\n",
      "313/313 [==============================] - 0s 272us/step - loss: 0.3230 - accuracy: 0.8872\n",
      "313/313 [==============================] - 0s 262us/step - loss: 0.3387 - accuracy: 0.8861\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4074 - accuracy: 0.8549\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3501 - accuracy: 0.8797\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3808 - accuracy: 0.8768\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.1000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.8821\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3457 - accuracy: 0.8879\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3503 - accuracy: 0.8713\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4555 - accuracy: 0.8627\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Investigacion\n",
    "###########################################\n",
    "\n",
    "ls_loss, ls_acc = [], []\n",
    "\n",
    "x,y = model.evaluate(test_images, test_labels)\n",
    "ls_loss.append(x)\n",
    "ls_acc.append(y)\n",
    "\n",
    "x,y = model2.evaluate(test_images, test_labels)\n",
    "ls_loss.append(x)\n",
    "ls_acc.append(y)\n",
    "\n",
    "x,y = model3.evaluate(test_images, test_labels)\n",
    "ls_loss.append(x)\n",
    "ls_acc.append(y)\n",
    "\n",
    "ls_loss.append(0)\n",
    "ls_acc.append(0)\n",
    "\n",
    "ls_loss.append(0)\n",
    "ls_acc.append(0)\n",
    "\n",
    "x,y = model6.evaluate(test_images, test_labels)\n",
    "ls_loss.append(x)\n",
    "ls_acc.append(y)\n",
    "\n",
    "x,y = model7.evaluate(test_images, test_labels)\n",
    "ls_loss.append(x)\n",
    "ls_acc.append(y)\n",
    "\n",
    "x,y = model8.evaluate(test_images, test_labels)\n",
    "ls_loss.append(x)\n",
    "ls_acc.append(y)\n",
    "\n",
    "x,y = model9.evaluate(test_images, test_labels)\n",
    "ls_loss.append(x)\n",
    "ls_acc.append(y)\n",
    "\n",
    "x,y = model10.evaluate(test_images, test_labels)\n",
    "ls_loss.append(x)\n",
    "ls_acc.append(y)\n",
    "\n",
    "x,y = model11.evaluate(test_images, test_labels)\n",
    "ls_loss.append(x)\n",
    "ls_acc.append(y)\n",
    "\n",
    "x,y = model12.evaluate(test_images, test_labels)\n",
    "ls_loss.append(x)\n",
    "ls_acc.append(y)\n",
    "\n",
    "x,y = model13.evaluate(test_images, test_labels)\n",
    "ls_loss.append(x)\n",
    "ls_acc.append(y)\n",
    "\n",
    "x,y = model14.evaluate(test_images, test_labels)\n",
    "ls_loss.append(x)\n",
    "ls_acc.append(y)\n",
    "\n",
    "x,y = model15.evaluate(test_images, test_labels)\n",
    "ls_loss.append(x)\n",
    "ls_acc.append(y)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>0.329032</td>\n",
       "      <td>0.8810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>0.327065</td>\n",
       "      <td>0.8850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model3</th>\n",
       "      <td>0.316116</td>\n",
       "      <td>0.8919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model6</th>\n",
       "      <td>0.323021</td>\n",
       "      <td>0.8872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model7</th>\n",
       "      <td>0.338702</td>\n",
       "      <td>0.8861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model8</th>\n",
       "      <td>0.407391</td>\n",
       "      <td>0.8549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model9</th>\n",
       "      <td>0.350058</td>\n",
       "      <td>0.8797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model10</th>\n",
       "      <td>0.380771</td>\n",
       "      <td>0.8768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model11</th>\n",
       "      <td>2.302608</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model12</th>\n",
       "      <td>0.347041</td>\n",
       "      <td>0.8821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model13</th>\n",
       "      <td>0.345723</td>\n",
       "      <td>0.8879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model14</th>\n",
       "      <td>0.350294</td>\n",
       "      <td>0.8713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model15</th>\n",
       "      <td>0.455548</td>\n",
       "      <td>0.8627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Loss  Accuracy\n",
       "model    0.329032    0.8810\n",
       "model2   0.327065    0.8850\n",
       "model3   0.316116    0.8919\n",
       "model4   0.000000    0.0000\n",
       "model5   0.000000    0.0000\n",
       "model6   0.323021    0.8872\n",
       "model7   0.338702    0.8861\n",
       "model8   0.407391    0.8549\n",
       "model9   0.350058    0.8797\n",
       "model10  0.380771    0.8768\n",
       "model11  2.302608    0.1000\n",
       "model12  0.347041    0.8821\n",
       "model13  0.345723    0.8879\n",
       "model14  0.350294    0.8713\n",
       "model15  0.455548    0.8627"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_table = pd.DataFrame({\"Loss\": ls_loss, \"Accuracy\": ls_acc}, index = [\"model\", \"model2\", \"model3\", \"model4\", \"model5\", \"model6\", \"model7\", \"model8\", \"model9\", \"model10\", \"model11\", \"model12\", \"model13\", \"model14\", \"model15\"])\n",
    "display(model_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "AUJ5AtunTFqa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.5633 - accuracy: 0.7927 - val_loss: 0.4082 - val_accuracy: 0.8525\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.3826 - accuracy: 0.8602 - val_loss: 0.4033 - val_accuracy: 0.8544\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 37s 19ms/step - loss: 0.3367 - accuracy: 0.8766 - val_loss: 0.3868 - val_accuracy: 0.8596\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.3098 - accuracy: 0.8850 - val_loss: 0.3423 - val_accuracy: 0.8774\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.2865 - accuracy: 0.8937 - val_loss: 0.3598 - val_accuracy: 0.8756\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.2697 - accuracy: 0.8984 - val_loss: 0.3374 - val_accuracy: 0.8815\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 37s 19ms/step - loss: 0.2533 - accuracy: 0.9042 - val_loss: 0.3658 - val_accuracy: 0.8729\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 37s 19ms/step - loss: 0.2407 - accuracy: 0.9091 - val_loss: 0.3515 - val_accuracy: 0.8717\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 37s 19ms/step - loss: 0.2265 - accuracy: 0.9130 - val_loss: 0.3126 - val_accuracy: 0.8893\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.2157 - accuracy: 0.9176 - val_loss: 0.3430 - val_accuracy: 0.8859\n",
      "============================================================\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3430 - accuracy: 0.8859\n",
      "\n",
      "El accuracy de este modelo al evaluarlo es: 0.8859000205993652 \n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# Creacion del Modelo\n",
    "###########################################\n",
    "\n",
    "_seed = 528\n",
    "\n",
    "# Creamos el modelo de Red Neuronal secuencial\n",
    "model16 = keras.models.Sequential()\n",
    "\n",
    "# Creamos la capa de entrada\n",
    "model16.add(keras.layers.Flatten(input_shape = sz_image))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model16.add(keras.layers.Dense(1024, activation = fun_hid_layer, kernel_initializer=initializers.GlorotUniform(seed=_seed)))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model16.add(keras.layers.Dense(1024, activation = fun_hid_layer, kernel_initializer=initializers.GlorotUniform(seed=_seed)))\n",
    "\n",
    "# Creamos una única capa oculta con 1024 neuronas\n",
    "model16.add(keras.layers.Dense(1024, activation = fun_hid_layer, kernel_initializer=initializers.GlorotUniform(seed=_seed)))\n",
    "\n",
    "# Creamos la capa de salida\n",
    "model16.add(keras.layers.Dense(tags, activation = fun_output_layer, kernel_initializer=initializers.GlorotUniform(seed=_seed)))\n",
    "\n",
    "# Modificamos los parámetros del modelo\n",
    "model16.compile(loss=\"sparse_categorical_crossentropy\", optimizer = \"Adam\", metrics = metr, steps_per_execution = sz_batch)\n",
    "\n",
    "\n",
    "\n",
    "###########################################\n",
    "# Ajuste del Modelo\n",
    "###########################################\n",
    "\n",
    "adj_model16 = model16.fit(training_images, training_labels, epochs = 10, validation_data=(test_images, test_labels))\n",
    "\n",
    "###########################################\n",
    "# Evaluacion del Modelo\n",
    "###########################################\n",
    "\n",
    "print(\"============================================================\")\n",
    "\n",
    "# Evaluamos el modelo según los valores test que nos proporcionan\n",
    "print(\"\\nEl accuracy de este modelo al evaluarlo es: {} \".format(model16.evaluate(test_images, test_labels)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Respuesta a la pregunta 12:</b>\n",
    "Para poder realizar una óptima red neuronal, he realizado primero un estudio comparando todos los modelos que se han ejecutado para saber de que modelo partir. Una vez realizado dicho estudio, he escogido el modelo 3 planteado en el código que contiene el modelo original con 1024 neuronas y una capa oculta.\n",
    "\n",
    "Posteriormente, le he agregado dos capas ocultas más (para mejorar el rendimiento) y le he puesto el initializer Glorot Uniform (que, mediante comparación con los demás optimizadores, se ha escogido por su accuracy). Todo esto se ha ido probando con varios modelos hasta encontrar el mejor. El principal problema que se ha encontrado es el descontrol de la inicializacion al no probar con una seed fija, ya que con el mismo modelo se ha llegado a accuracy entre 0,88 y 0.92 en varias ejecuciones, por lo tanto, se ha ido probando al final seed fijas."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
